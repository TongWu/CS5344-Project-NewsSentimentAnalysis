{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "authorship_tag": "ABX9TyMbu7oHkgMvVszGxsyd8yKV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TongWu/CS5344-Project-NewsSentimentAnalysis/blob/main/Notebooks/RF_RAndomSEarch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3tjYcZ_YMX_"
      },
      "outputs": [],
      "source": [
        "# !pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "0ztJCfEua-II",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98e1c06c-e844-4742-e883-abd95aa86ab0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# conda install -c conda-forge cudatoolkit=11.2 cudnn=8.1.0"
      ],
      "metadata": {
        "id": "8O-jBSn0yq33"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install \"numpy<2.0\" \"tensorflow==2.10\""
      ],
      "metadata": {
        "id": "ZE5AXdbNXT_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install pandas transformers optuna scikit-learn"
      ],
      "metadata": {
        "id": "8P_YtcyPWgxQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Import Libraries and Set Up Environment\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "import tensorflow as tf\n",
        "from transformers import RobertaTokenizer, TFRobertaModel\n",
        "\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "import optuna\n",
        "from optuna.integration import TFKerasPruningCallback\n",
        "\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "import os\n",
        "import random\n",
        "from tqdm import tqdm  # Added tqdm for progress visualization\n",
        "import h5py  # Added h5py for saving data\n",
        "\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "# Initialize GPU settings if available\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        logical_gpus = tf.config.list_logical_devices('GPU')\n",
        "        print(len(gpus), \"physical GPUs,\", len(logical_gpus), \"logical GPUs.\")\n",
        "    except RuntimeError as e:\n",
        "        print(e)"
      ],
      "metadata": {
        "id": "lZtP0CY5yb0w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "055b21d6-80fa-455c-f4d3-cb6f7f6a6ecc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 physical GPUs, 1 logical GPUs.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Load the entire dataset (without chunking)\n",
        "# print(\"Loading the dataset...\")\n",
        "# data_path = \"./Downloads/ggg_sg.csv\"\n",
        "# usecols = ['DateTime', 'Title', 'DomainCountryCode', 'ContextualText', 'DocTone']\n",
        "# df = pd.read_csv(data_path, usecols=usecols)\n",
        "# df_filtered = df[['ContextualText', 'DocTone']].dropna(subset=['ContextualText', 'DocTone'])\n",
        "# df_filtered['DocTone'] = df_filtered['DocTone'].astype(float)\n",
        "# # Initialize variables to store label encoder classes\n",
        "# label_encoder = LabelEncoder()\n",
        "\n",
        "# # Compute quantiles\n",
        "# percentiles = [0.2, 0.4, 0.6, 0.8]\n",
        "# quantiles = df_filtered['DocTone'].quantile(percentiles)\n",
        "# print(\"DocTone quantile thresholds:\", quantiles.values)\n",
        "# q1, q2, q3, q4 = quantiles.values\n",
        "\n",
        "# # Function to label sentiment\n",
        "# def label_sentiment(score):\n",
        "#     if score <= q1:\n",
        "#         return 'Strongly Negative'\n",
        "#     elif q1 < score <= q2:\n",
        "#         return 'Negative'\n",
        "#     elif q2 < score <= q3:\n",
        "#         return 'Neutral'\n",
        "#     elif q3 < score <= q4:\n",
        "#         return 'Positive'\n",
        "#     else:\n",
        "#         return 'Strongly Positive'\n",
        "\n",
        "# # Apply the sentiment labeling\n",
        "# df_filtered['Sentiment'] = df_filtered['DocTone'].apply(label_sentiment)\n",
        "\n",
        "# # Encode sentiments\n",
        "# df_filtered['SentimentLabel'] = label_encoder.fit_transform(df_filtered['Sentiment'])\n",
        "# num_labels = len(label_encoder.classes_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BO6i67y63mrb",
        "outputId": "c8b93675-78c0-4577-bd08-939df5466bf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading the dataset...\n",
            "DocTone quantile thresholds: [-2.58706468 -0.65502183  0.79928952  2.47191011]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(num_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4cBjF0obAdK",
        "outputId": "91f5d733-acdf-44b5-91ed-0309bad93eea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# h5f.close()"
      ],
      "metadata": {
        "id": "Eew76HTU39-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Step 2: Load and Preprocess Data\n",
        "# # Prepare h5py file to store processed data\n",
        "# h5_file = 'processed_data.h5'\n",
        "# if os.path.exists(h5_file):\n",
        "#     os.remove(h5_file)\n",
        "\n",
        "# h5f = h5py.File(h5_file, 'w')\n",
        "\n",
        "# # We will need to determine the max_length for tokenization\n",
        "# max_length = 1024  # Adjust as needed\n",
        "\n",
        "# # Initialize tokenizer and model\n",
        "# model_name = 'roberta-base'\n",
        "# tokenizer = RobertaTokenizer.from_pretrained(model_name)\n",
        "# transformer_model = TFRobertaModel.from_pretrained(model_name)\n",
        "\n",
        "# # Create datasets in h5py file with maxshape set to None to allow resizing\n",
        "# input_ids_dataset = h5f.create_dataset('input_ids', shape=(0, max_length), maxshape=(None, max_length), dtype='int32')\n",
        "# attention_masks_dataset = h5f.create_dataset('attention_masks', shape=(0, max_length), maxshape=(None, max_length), dtype='int32')\n",
        "# labels_dataset = h5f.create_dataset('labels', shape=(0,), maxshape=(None,), dtype='int32')\n",
        "\n",
        "# # Tokenize the texts and save to h5py in chunks\n",
        "# print(\"Tokenizing texts and saving to h5py file in batches...\")\n",
        "# texts = df_filtered['ContextualText'].tolist()\n",
        "# labels = df_filtered['SentimentLabel'].values\n",
        "\n",
        "# batch_size = 2  # Adjust based on your memory capacity\n",
        "# total_samples = 0  # Keep track of the total number of samples processed\n",
        "\n",
        "# for i in tqdm(range(0, len(texts), batch_size), desc=\"Processing Batches\"):\n",
        "#     texts_batch = texts[i:i+batch_size]\n",
        "#     labels_batch = labels[i:i+batch_size]\n",
        "#     encoded = tokenizer(\n",
        "#         texts_batch,\n",
        "#         add_special_tokens=True,\n",
        "#         max_length=max_length,\n",
        "#         padding='max_length',\n",
        "#         truncation=True,\n",
        "#         return_attention_mask=True,\n",
        "#         return_tensors='np'  # Return numpy arrays\n",
        "#     )\n",
        "#     input_ids = encoded['input_ids']\n",
        "#     attention_masks = encoded['attention_mask']\n",
        "\n",
        "#     batch_size_actual = input_ids.shape[0]  # In case the last batch is smaller\n",
        "\n",
        "#     # Resize datasets to accommodate new data\n",
        "#     input_ids_dataset.resize((total_samples + batch_size_actual, max_length))\n",
        "#     input_ids_dataset[total_samples:total_samples + batch_size_actual] = input_ids\n",
        "\n",
        "#     attention_masks_dataset.resize((total_samples + batch_size_actual, max_length))\n",
        "#     attention_masks_dataset[total_samples:total_samples + batch_size_actual] = attention_masks\n",
        "\n",
        "#     labels_dataset.resize((total_samples + batch_size_actual,))\n",
        "#     labels_dataset[total_samples:total_samples + batch_size_actual] = labels_batch\n",
        "\n",
        "#     total_samples += batch_size_actual  # Update total samples processed\n",
        "\n",
        "# # Close the h5py file\n",
        "# h5f.close()\n",
        "\n"
      ],
      "metadata": {
        "id": "BQLXnxeIzMNu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b803af55-d66c-4ea9-ed1a-06b24c8abe62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'roberta.embeddings.position_ids', 'lm_head.bias']\n",
            "- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights or buffers of the TF 2.0 model TFRobertaModel were not initialized from the PyTorch model and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizing texts and saving to h5py file in batches...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Batches: 100%|████████████████████████████████████████████████| 4592653/4592653 [1:11:32<00:00, 1070.03it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Load Processed Data from h5py File\n",
        "print(\"Loading processed data from h5py file...\")\n",
        "h5_file = 'processed_data.h5'\n",
        "h5f = h5py.File(h5_file, 'r')\n",
        "input_ids = np.array(h5f['input_ids'])\n",
        "attention_masks = np.array(h5f['attention_masks'])\n",
        "labels = h5f['labels']\n",
        "\n",
        "# Convert labels to numpy array\n",
        "labels = np.array(labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSRUT-SizZs4",
        "outputId": "1bdad01b-d554-42ca-e42b-24cf609505bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading processed data from h5py file...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Split Data into Train and Test Sets\n",
        "print(\"Splitting data into train and test sets...\")\n",
        "labels = np.array(labels)\n",
        "X_train_ids, X_test_ids, X_train_masks, X_test_masks, y_train, y_test = train_test_split(\n",
        "    input_ids,\n",
        "    attention_masks,\n",
        "    labels,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=labels\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kV8A6I3u6WCj",
        "outputId": "82cd9fd0-90e9-4d25-acfa-4a34bc1801de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Splitting data into train and test sets...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save in one shot\n",
        "with h5py.File('roberta_train_test_data.h5', 'w') as f:\n",
        "    f.create_dataset('X_train_ids', data=X_train_ids)\n",
        "    f.create_dataset('X_test_ids', data=X_test_ids)\n",
        "    f.create_dataset('X_train_masks', data=X_train_masks)\n",
        "    f.create_dataset('X_test_masks', data=X_test_masks)\n",
        "    f.create_dataset('y_train', data=y_train)\n",
        "    f.create_dataset('y_test', data=y_test)"
      ],
      "metadata": {
        "id": "1UEDS5K4sSy4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save by train/test\n",
        "with h5py.File('roberta_train_data.h5', 'w') as train_file:\n",
        "    train_file.create_dataset('X_train_ids', data=X_train_ids)\n",
        "    train_file.create_dataset('X_train_masks', data=X_train_masks)\n",
        "    train_file.create_dataset('y_train', data=y_train)\n",
        "\n",
        "with h5py.File('roberta_test_data.h5', 'w') as test_file:\n",
        "    test_file.create_dataset('X_test_ids', data=X_test_ids)\n",
        "    test_file.create_dataset('X_test_masks', data=X_test_masks)\n",
        "    test_file.create_dataset('y_test', data=y_test)"
      ],
      "metadata": {
        "id": "oZzCOuUkvO3L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save individually\n",
        "with h5py.File('roberta_X_train_ids.h5', 'w') as f:\n",
        "    f.create_dataset('X_train_ids', data=X_train_ids)\n",
        "\n",
        "with h5py.File('roberta_X_test_ids.h5', 'w') as f:\n",
        "    f.create_dataset('X_test_ids', data=X_test_ids)\n",
        "\n",
        "with h5py.File('roberta_X_train_masks.h5', 'w') as f:\n",
        "    f.create_dataset('X_train_masks', data=X_train_masks)\n",
        "\n",
        "with h5py.File('roberta_X_test_masks.h5', 'w') as f:\n",
        "    f.create_dataset('X_test_masks', data=X_test_masks)\n",
        "\n",
        "with h5py.File('roberta_y_train.h5', 'w') as f:\n",
        "    f.create_dataset('y_train', data=y_train)\n",
        "\n",
        "with h5py.File('roberta_y_test.h5', 'w') as f:\n",
        "    f.create_dataset('y_test', data=y_test)"
      ],
      "metadata": {
        "id": "0e_I_9Uzv2-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# with h5py.File('/content/roberta_train_test_data.h5', 'r') as f:\n",
        "#     X_train_ids = f['X_train_ids'][:]\n",
        "#     X_test_ids = f['X_test_ids'][:]\n",
        "#     X_train_masks = f['X_train_masks'][:]\n",
        "#     X_test_masks = f['X_test_masks'][:]\n",
        "#     y_train = f['y_train'][:]\n",
        "#     y_test = f['y_test'][:]\n",
        "with h5py.File('roberta_train_data.h5', 'r') as train_file:\n",
        "    X_train_ids = train_file['X_train_ids'][:]\n",
        "    X_train_masks = train_file['X_train_masks'][:]\n",
        "    y_train = train_file['y_train'][:]\n",
        "\n",
        "with h5py.File('roberta_test_data.h5', 'r') as test_file:\n",
        "    X_test_ids = test_file['X_test_ids'][:]\n",
        "    X_test_masks = test_file['X_test_masks'][:]\n",
        "    y_test = test_file['y_test'][:]"
      ],
      "metadata": {
        "id": "-rJUN-AIucc6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Compute Class Weights\n",
        "print(\"Computing class weights...\")\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
        "class_weight_dict = dict(enumerate(class_weights))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JkiBUkWIwE8h",
        "outputId": "4dd6c577-7b1b-4088-bbd3-a6e86670aafc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing class weights...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up mixed precision training\n",
        "from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
        "\n",
        "policy = mixed_precision.Policy('mixed_float16')\n",
        "mixed_precision.set_policy(policy)"
      ],
      "metadata": {
        "id": "1XEWTwF3t-U_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Define Function to Build the Model\n",
        "def build_model(transformer_model, learning_rate, dropout_rate, dense_units):\n",
        "    input_ids_in = tf.keras.Input(shape=(max_length,), dtype=tf.int32, name='input_ids')\n",
        "    input_masks_in = tf.keras.Input(shape=(max_length,), dtype=tf.int32, name='attention_mask')\n",
        "\n",
        "    # Get transformer outputs\n",
        "    outputs = transformer_model(input_ids_in, attention_mask=input_masks_in)\n",
        "    cls_token = outputs.last_hidden_state[:, 0, :]  # [CLS] token\n",
        "\n",
        "    x = tf.keras.layers.Dropout(dropout_rate)(cls_token)\n",
        "    x = tf.keras.layers.Dense(dense_units, activation='relu')(x)\n",
        "    x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
        "    output = tf.keras.layers.Dense(num_labels, activation='softmax', dtype='float32')(x)\n",
        "\n",
        "    model = tf.keras.Model(inputs=[input_ids_in, input_masks_in], outputs=output)\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "    optimizer = mixed_precision.LossScaleOptimizer(optimizer, loss_scale='dynamic')\n",
        "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "OEf1xN-dfw5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Hyperparameter Optimization with Optuna\n",
        "def objective(trial):\n",
        "    # Clear session and collect garbage\n",
        "    tf.keras.backend.clear_session()\n",
        "    gc.collect()\n",
        "\n",
        "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 5e-5, log=True)\n",
        "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.3)\n",
        "    dense_units = trial.suggest_int('dense_units', 64, 128, step=32)\n",
        "    batch_size = trial.suggest_categorical('batch_size', [1, 2, 4])  # Reduced batch size\n",
        "\n",
        "    model = build_model(transformer_model, learning_rate, dropout_rate, dense_units)\n",
        "\n",
        "    # Use data generators to optimize memory usage\n",
        "    train_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "        {'input_ids': X_train_ids, 'attention_mask': X_train_masks}, y_train))\n",
        "    train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
        "\n",
        "    val_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "        {'input_ids': X_test_ids, 'attention_mask': X_test_masks}, y_test))\n",
        "    val_dataset = val_dataset.batch(batch_size)\n",
        "\n",
        "    epochs = 3\n",
        "    history = model.fit(\n",
        "        train_dataset,\n",
        "        validation_data=val_dataset,\n",
        "        epochs=epochs,\n",
        "        class_weight=class_weight_dict,\n",
        "        callbacks=[TFKerasPruningCallback(trial, 'val_accuracy')],\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    val_accuracy = max(history.history['val_accuracy'])\n",
        "\n",
        "    # Clean up\n",
        "    del model\n",
        "    tf.keras.backend.clear_session()\n",
        "    gc.collect()\n",
        "\n",
        "    return val_accuracy\n",
        "\n",
        "# Initialize tokenizer and model\n",
        "model_name = 'roberta-base'\n",
        "tokenizer = RobertaTokenizer.from_pretrained(model_name)\n",
        "transformer_model = TFRobertaModel.from_pretrained(model_name)\n",
        "transformer_model.trainable = False  # Freeze all layers\n",
        "max_length = 256\n",
        "num_labels = 5\n",
        "print(\"Starting hyperparameter optimization with Optuna...\")\n",
        "n_trials = 10\n",
        "study = optuna.create_study(direction='maximize')\n",
        "\n",
        "# Initialize tqdm progress bar\n",
        "with tqdm(total=n_trials, desc=\"Optuna Trials\") as progress_bar:\n",
        "    study.optimize(objective, n_trials=n_trials)\n",
        "\n",
        "print(\"Best hyperparameters:\")\n",
        "print(study.best_params)"
      ],
      "metadata": {
        "id": "l0k-Pxz_g0wj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "14380ff4-bfea-4a3b-a882-e972f8a718bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'roberta.embeddings.position_ids', 'lm_head.layer_norm.weight']\n",
            "- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights or buffers of the TF 2.0 model TFRobertaModel were not initialized from the PyTorch model and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "[I 2024-11-03 00:12:25,576] A new study created in memory with name: no-name-38cd4656-fd6e-4044-b868-c45b51797dd8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting hyperparameter optimization with Optuna...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rOptuna Trials:   0%|                                                                            | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[W 2024-11-03 00:12:45,804] Trial 0 failed with parameters: {'learning_rate': 2.9583927785361854e-05, 'dropout_rate': 0.40572572078492986, 'dense_units': 64, 'batch_size': 4} because of the following error: ResourceExhaustedError().\n",
            "Traceback (most recent call last):\n",
            "  File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "  File \"C:\\Users\\Ted Wu\\AppData\\Local\\Temp\\ipykernel_24216\\2435040825.py\", line 11, in objective\n",
            "    history = model.fit(\n",
            "  File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n",
            "    raise e.with_traceback(filtered_tb) from None\n",
            "  File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\", line 54, in quick_execute\n",
            "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
            "tensorflow.python.framework.errors_impl.ResourceExhaustedError: Graph execution error:\n",
            "\n",
            "Detected at node 'model/tf_roberta_model/roberta/encoder/layer_._11/attention/self/MatMul' defined at (most recent call last):\n",
            "    File \"D:\\anaconda3\\envs\\ww\\lib\\runpy.py\", line 197, in _run_module_as_main\n",
            "      return _run_code(code, main_globals, None,\n",
            "    File \"D:\\anaconda3\\envs\\ww\\lib\\runpy.py\", line 87, in _run_code\n",
            "      exec(code, run_globals)\n",
            "    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
            "      app.launch_new_instance()\n",
            "    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
            "      app.start()\n",
            "    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
            "      self.io_loop.start()\n",
            "    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
            "      self.asyncio_loop.run_forever()\n",
            "    File \"D:\\anaconda3\\envs\\ww\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n",
            "      self._run_once()\n",
            "    File \"D:\\anaconda3\\envs\\ww\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n",
            "      handle._run()\n",
            "    File \"D:\\anaconda3\\envs\\ww\\lib\\asyncio\\events.py\", line 80, in _run\n",
            "      self._context.run(self._callback, *self._args)\n",
            "    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
            "      await self.process_one()\n",
            "    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
            "      await dispatch(*args)\n",
            "    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
            "      await result\n",
            "    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
            "      await super().execute_request(stream, ident, parent)\n",
            "    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
            "      reply_content = await reply_content\n",
            "    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
            "      res = shell.run_cell(\n",
            "    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
            "      return super().run_cell(*args, **kwargs)\n",
            "    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n",
            "      result = self._run_cell(\n",
            "    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n",
            "      result = runner(coro)\n",
            "    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
            "      coro.send(None)\n",
            "    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n",
            "      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
            "    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n",
            "      if await self.run_code(code, result, async_=asy):\n",
            "    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n",
            "      exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "    File \"C:\\Users\\Ted Wu\\AppData\\Local\\Temp\\ipykernel_24216\\2435040825.py\", line 40, in <module>\n",
            "      study.optimize(objective, n_trials=n_trials)\n",
            "    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\optuna\\study\\study.py\", line 475, in optimize\n",
            "      _optimize(\n",
            "    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 63, in _optimize\n",
            "      _optimize_sequential(\n",
            "    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 160, in _optimize_sequential\n",
            "      frozen_trial = _run_trial(study, func, catch)\n",
            "    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
            "      value_or_values = func(trial)\n",
            "    File \"C:\\Users\\Ted Wu\\AppData\\Local\\Temp\\ipykernel_24216\\2435040825.py\", line 11, in objective\n",
            "      history = model.fit(\n",
            "    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n",
            "      return fn(*args, **kwargs)\n",
            "    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n",
            "      tmp_logs = self.train_function(iterator)\n",
            "    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n",
            "      return step_function(self, iterator)\n",
            "    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n",
            "      outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
            "    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n",
            "      outputs = model.train_step(data)\n",
            "    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n",
            "      y_pred = self(x, training=True)\n",
            "    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n",
            "      return fn(*args, **kwargs)\n",
            "    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n",
            "      return super().__call__(*args, **kwargs)\n",
            "    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n",
            "      return fn(*args, **kwargs)\n",
            "    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n",
            "      outputs = call_fn(inputs, *args, **kwargs)\n",
            "    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n",
            "      return fn(*args, **kwargs)\n",
            "    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n",
            "      return self._run_internal_graph(inputs, training=training, mask=mask)\n",
            "    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n",
            "      outputs = node.layer(*args, **kwargs)\n",
            "    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n",
            "      return fn(*args, **kwargs)\n",
            "    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n",
            "      return super().__call__(*args, **kwargs)\n",
            "    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n",
            "      return fn(*args, **kwargs)\n",
            "    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n",
            "      outputs = call_fn(inputs, *args, **kwargs)\n",
            "    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n",
            "      return fn(*args, **kwargs)\n",
            "    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1008, in run_call_with_unpacked_inputs\n",
            "      else:\n",
            "    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\transformers\\models\\roberta\\modeling_tf_roberta.py\", line 1035, in call\n",
            "      outputs = self.roberta(\n",
            "    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n",
            "      return fn(*args, **kwargs)\n",
            "    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n",
            "      outputs = call_fn(inputs, *args, **kwargs)\n",
            "    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n",
            "      return fn(*args, **kwargs)\n",
            "    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1008, in run_call_with_unpacked_inputs\n",
            "      else:\n",
            "    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\transformers\\models\\roberta\\modeling_tf_roberta.py\", line 827, in call\n",
            "      encoder_outputs = self.encoder(\n",
            "    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n",
            "      return fn(*args, **kwargs)\n",
            "    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n",
            "      outputs = call_fn(inputs, *args, **kwargs)\n",
            "    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n",
            "      return fn(*args, **kwargs)\n",
            "    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\transformers\\models\\roberta\\modeling_tf_roberta.py\", line 610, in call\n",
            "      for i, layer_module in enumerate(self.layer):\n",
            "    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\transformers\\models\\roberta\\modeling_tf_roberta.py\", line 616, in call\n",
            "      layer_outputs = layer_module(\n",
            "    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n",
            "      return fn(*args, **kwargs)\n",
            "    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n",
            "      outputs = call_fn(inputs, *args, **kwargs)\n",
            "    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n",
            "      return fn(*args, **kwargs)\n",
            "    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\transformers\\models\\roberta\\modeling_tf_roberta.py\", line 508, in call\n",
            "      self_attention_outputs = self.attention(\n",
            "    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n",
            "      return fn(*args, **kwargs)\n",
            "    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n",
            "      outputs = call_fn(inputs, *args, **kwargs)\n",
            "    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n",
            "      return fn(*args, **kwargs)\n",
            "    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\transformers\\models\\roberta\\modeling_tf_roberta.py\", line 389, in call\n",
            "      self_outputs = self.self_attention(\n",
            "    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n",
            "      return fn(*args, **kwargs)\n",
            "    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n",
            "      outputs = call_fn(inputs, *args, **kwargs)\n",
            "    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n",
            "      return fn(*args, **kwargs)\n",
            "    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\transformers\\models\\roberta\\modeling_tf_roberta.py\", line 291, in call\n",
            "      attention_scores = tf.matmul(query_layer, key_layer, transpose_b=True)\n",
            "Node: 'model/tf_roberta_model/roberta/encoder/layer_._11/attention/self/MatMul'\n",
            "OOM when allocating tensor with shape[4,12,1024,1024] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
            "\t [[{{node model/tf_roberta_model/roberta/encoder/layer_._11/attention/self/MatMul}}]]\n",
            "Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n",
            " [Op:__inference_train_function_50919]\n",
            "[W 2024-11-03 00:12:45,805] Trial 0 failed with value None.\n",
            "Optuna Trials:   0%|                                                                            | 0/10 [00:20<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "Graph execution error:\n\nDetected at node 'model/tf_roberta_model/roberta/encoder/layer_._11/attention/self/MatMul' defined at (most recent call last):\n    File \"D:\\anaconda3\\envs\\ww\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"D:\\anaconda3\\envs\\ww\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n      app.launch_new_instance()\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n      app.start()\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n      self.io_loop.start()\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n      self.asyncio_loop.run_forever()\n    File \"D:\\anaconda3\\envs\\ww\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"D:\\anaconda3\\envs\\ww\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"D:\\anaconda3\\envs\\ww\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n      await self.process_one()\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n      await dispatch(*args)\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n      await result\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n      await super().execute_request(stream, ident, parent)\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n      reply_content = await reply_content\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n      res = shell.run_cell(\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n      result = self._run_cell(\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n      result = runner(coro)\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Ted Wu\\AppData\\Local\\Temp\\ipykernel_24216\\2435040825.py\", line 40, in <module>\n      study.optimize(objective, n_trials=n_trials)\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\optuna\\study\\study.py\", line 475, in optimize\n      _optimize(\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 63, in _optimize\n      _optimize_sequential(\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 160, in _optimize_sequential\n      frozen_trial = _run_trial(study, func, catch)\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n      value_or_values = func(trial)\n    File \"C:\\Users\\Ted Wu\\AppData\\Local\\Temp\\ipykernel_24216\\2435040825.py\", line 11, in objective\n      history = model.fit(\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1008, in run_call_with_unpacked_inputs\n      else:\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\transformers\\models\\roberta\\modeling_tf_roberta.py\", line 1035, in call\n      outputs = self.roberta(\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1008, in run_call_with_unpacked_inputs\n      else:\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\transformers\\models\\roberta\\modeling_tf_roberta.py\", line 827, in call\n      encoder_outputs = self.encoder(\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\transformers\\models\\roberta\\modeling_tf_roberta.py\", line 610, in call\n      for i, layer_module in enumerate(self.layer):\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\transformers\\models\\roberta\\modeling_tf_roberta.py\", line 616, in call\n      layer_outputs = layer_module(\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\transformers\\models\\roberta\\modeling_tf_roberta.py\", line 508, in call\n      self_attention_outputs = self.attention(\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\transformers\\models\\roberta\\modeling_tf_roberta.py\", line 389, in call\n      self_outputs = self.self_attention(\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\transformers\\models\\roberta\\modeling_tf_roberta.py\", line 291, in call\n      attention_scores = tf.matmul(query_layer, key_layer, transpose_b=True)\nNode: 'model/tf_roberta_model/roberta/encoder/layer_._11/attention/self/MatMul'\nOOM when allocating tensor with shape[4,12,1024,1024] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model/tf_roberta_model/roberta/encoder/layer_._11/attention/self/MatMul}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_50919]",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[10], line 40\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Initialize tqdm progress bar\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tqdm(total\u001b[38;5;241m=\u001b[39mn_trials, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptuna Trials\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m progress_bar:\n\u001b[1;32m---> 40\u001b[0m     \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest hyperparameters:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(study\u001b[38;5;241m.\u001b[39mbest_params)\n",
            "File \u001b[1;32mD:\\anaconda3\\envs\\ww\\lib\\site-packages\\optuna\\study\\study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    385\u001b[0m \n\u001b[0;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mD:\\anaconda3\\envs\\ww\\lib\\site-packages\\optuna\\study\\_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
            "File \u001b[1;32mD:\\anaconda3\\envs\\ww\\lib\\site-packages\\optuna\\study\\_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
            "File \u001b[1;32mD:\\anaconda3\\envs\\ww\\lib\\site-packages\\optuna\\study\\_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    247\u001b[0m ):\n\u001b[1;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
            "File \u001b[1;32mD:\\anaconda3\\envs\\ww\\lib\\site-packages\\optuna\\study\\_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
            "Cell \u001b[1;32mIn[10], line 11\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m      8\u001b[0m model \u001b[38;5;241m=\u001b[39m build_model(learning_rate, dropout_rate, dense_units)\n\u001b[0;32m     10\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[1;32m---> 11\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_train_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_masks\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mTFKerasPruningCallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval_accuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\n\u001b[0;32m     20\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m val_accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     23\u001b[0m progress_bar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m1\u001b[39m)\n",
            "File \u001b[1;32mD:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[1;32mD:\\anaconda3\\envs\\ww\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'model/tf_roberta_model/roberta/encoder/layer_._11/attention/self/MatMul' defined at (most recent call last):\n    File \"D:\\anaconda3\\envs\\ww\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"D:\\anaconda3\\envs\\ww\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n      app.launch_new_instance()\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n      app.start()\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n      self.io_loop.start()\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n      self.asyncio_loop.run_forever()\n    File \"D:\\anaconda3\\envs\\ww\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"D:\\anaconda3\\envs\\ww\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"D:\\anaconda3\\envs\\ww\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n      await self.process_one()\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n      await dispatch(*args)\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n      await result\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n      await super().execute_request(stream, ident, parent)\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n      reply_content = await reply_content\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n      res = shell.run_cell(\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n      result = self._run_cell(\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n      result = runner(coro)\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Ted Wu\\AppData\\Local\\Temp\\ipykernel_24216\\2435040825.py\", line 40, in <module>\n      study.optimize(objective, n_trials=n_trials)\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\optuna\\study\\study.py\", line 475, in optimize\n      _optimize(\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 63, in _optimize\n      _optimize_sequential(\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 160, in _optimize_sequential\n      frozen_trial = _run_trial(study, func, catch)\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n      value_or_values = func(trial)\n    File \"C:\\Users\\Ted Wu\\AppData\\Local\\Temp\\ipykernel_24216\\2435040825.py\", line 11, in objective\n      history = model.fit(\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1008, in run_call_with_unpacked_inputs\n      else:\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\transformers\\models\\roberta\\modeling_tf_roberta.py\", line 1035, in call\n      outputs = self.roberta(\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1008, in run_call_with_unpacked_inputs\n      else:\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\transformers\\models\\roberta\\modeling_tf_roberta.py\", line 827, in call\n      encoder_outputs = self.encoder(\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\transformers\\models\\roberta\\modeling_tf_roberta.py\", line 610, in call\n      for i, layer_module in enumerate(self.layer):\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\transformers\\models\\roberta\\modeling_tf_roberta.py\", line 616, in call\n      layer_outputs = layer_module(\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\transformers\\models\\roberta\\modeling_tf_roberta.py\", line 508, in call\n      self_attention_outputs = self.attention(\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\transformers\\models\\roberta\\modeling_tf_roberta.py\", line 389, in call\n      self_outputs = self.self_attention(\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\anaconda3\\envs\\ww\\lib\\site-packages\\transformers\\models\\roberta\\modeling_tf_roberta.py\", line 291, in call\n      attention_scores = tf.matmul(query_layer, key_layer, transpose_b=True)\nNode: 'model/tf_roberta_model/roberta/encoder/layer_._11/attention/self/MatMul'\nOOM when allocating tensor with shape[4,12,1024,1024] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model/tf_roberta_model/roberta/encoder/layer_._11/attention/self/MatMul}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_50919]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 8: Build and Train the Final Model with Best Hyperparameters\n",
        "best_params = study.best_params\n",
        "learning_rate = best_params['learning_rate']\n",
        "dropout_rate = best_params['dropout_rate']\n",
        "dense_units = best_params['dense_units']\n",
        "batch_size = best_params['batch_size']\n",
        "\n",
        "model = build_model(learning_rate, dropout_rate, dense_units)\n",
        "\n",
        "# Set up callbacks\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=1)\n",
        "\n",
        "print(\"Training the final model...\")\n",
        "epochs = 5  # Adjust as needed\n",
        "history = model.fit(\n",
        "    [X_train_ids, X_train_masks],\n",
        "    y_train,\n",
        "    validation_data=([X_test_ids, X_test_masks], y_test),\n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        "    class_weight=class_weight_dict,\n",
        "    callbacks=[early_stopping, reduce_lr]\n",
        ")\n",
        "model.save(\"saved_model\")\n",
        "model.save(\"final_model.h5\")"
      ],
      "metadata": {
        "id": "-oU_9dbcCafT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 9: Evaluate the Transformer Model\n",
        "print(\"Evaluating the transformer model...\")\n",
        "y_pred_probs = model.predict([X_test_ids, X_test_masks], batch_size=batch_size)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "# Output performance metrics\n",
        "print(\"Transformer Model Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
        "\n",
        "print(\"Transformer Model Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Transformer Model Precision:\", precision_score(y_test, y_pred, average='weighted'))\n",
        "print(\"Transformer Model Recall:\", recall_score(y_test, y_pred, average='weighted'))\n",
        "print(\"Transformer Model F1 Score:\", f1_score(y_test, y_pred, average='weighted'))"
      ],
      "metadata": {
        "id": "CXglu4r1iuve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 10: Extract Embeddings and Train Random Forest Classifier\n",
        "print(\"Extracting embeddings from the fine-tuned model...\")\n",
        "# Define a new model to output embeddings\n",
        "embedding_model = tf.keras.Model(inputs=model.inputs, outputs=model.layers[-3].output)  # Output before the last dense layer\n",
        "\n",
        "print(\"Getting embeddings for training and test data...\")\n",
        "X_train_embeddings = embedding_model.predict([X_train_ids, X_train_masks], batch_size=batch_size)\n",
        "X_test_embeddings = embedding_model.predict([X_test_ids, X_test_masks], batch_size=batch_size)\n",
        "\n",
        "# Save embeddings to h5py file\n",
        "print(\"Saving embeddings to h5py file...\")\n",
        "embeddings_file = 'embeddings.h5'\n",
        "if os.path.exists(embeddings_file):\n",
        "    os.remove(embeddings_file)\n",
        "emb_h5f = h5py.File(embeddings_file, 'w')\n",
        "emb_h5f.create_dataset('X_train_embeddings', data=X_train_embeddings)\n",
        "emb_h5f.create_dataset('X_test_embeddings', data=X_test_embeddings)\n",
        "emb_h5f.close()\n"
      ],
      "metadata": {
        "id": "zZ9sSDK_qTzR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 11: Hyperparameter Tuning and Training Random Forest Classifier\n",
        "print(\"Starting hyperparameter tuning for Random Forest with Optuna...\")\n",
        "def rf_objective(trial):\n",
        "    n_estimators = trial.suggest_int('n_estimators', 100, 500, step=100)\n",
        "    max_depth = trial.suggest_int('max_depth', 5, 30, step=5)\n",
        "    min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n",
        "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 5)\n",
        "    max_features = trial.suggest_categorical('max_features', ['auto', 'sqrt', 'log2'])\n",
        "\n",
        "    rf = RandomForestClassifier(\n",
        "        n_estimators=n_estimators,\n",
        "        max_depth=max_depth,\n",
        "        min_samples_split=min_samples_split,\n",
        "        min_samples_leaf=min_samples_leaf,\n",
        "        max_features=max_features,\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "    rf.fit(X_train_embeddings, y_train)\n",
        "    y_pred_rf = rf.predict(X_test_embeddings)\n",
        "    return accuracy_score(y_test, y_pred_rf)\n",
        "\n",
        "rf_study = optuna.create_study(direction='maximize')\n",
        "rf_study.optimize(rf_objective, n_trials=10)\n",
        "\n",
        "print(\"Random Forest Best Hyperparameters:\")\n",
        "print(rf_study.best_params)\n",
        "\n",
        "# Train Random Forest with best parameters\n",
        "best_rf_params = rf_study.best_params\n",
        "rf = RandomForestClassifier(\n",
        "    n_estimators=best_rf_params['n_estimators'],\n",
        "    max_depth=best_rf_params['max_depth'],\n",
        "    min_samples_split=best_rf_params['min_samples_split'],\n",
        "    min_samples_leaf=best_rf_params['min_samples_leaf'],\n",
        "    max_features=best_rf_params['max_features'],\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "print(\"Training Random Forest Classifier...\")\n",
        "rf.fit(X_train_embeddings, y_train)"
      ],
      "metadata": {
        "id": "-Pw7yZDYtCNQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 12: Evaluate the Random Forest Model\n",
        "print(\"Evaluating the Random Forest model...\")\n",
        "y_pred_rf = rf.predict(X_test_embeddings)\n",
        "\n",
        "print(\"Random Forest Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_rf, target_names=label_encoder.classes_))\n",
        "\n",
        "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
        "print(\"Random Forest Precision:\", precision_score(y_test, y_pred_rf, average='weighted'))\n",
        "print(\"Random Forest Recall:\", recall_score(y_test, y_pred_rf, average='weighted'))\n",
        "print(\"Random Forest F1 Score:\", f1_score(y_test, y_pred_rf, average='weighted'))\n",
        "\n",
        "# Close the h5py files\n",
        "h5f.close()"
      ],
      "metadata": {
        "id": "pVluh03wtEdZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}