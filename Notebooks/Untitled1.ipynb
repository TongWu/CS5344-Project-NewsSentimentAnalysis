{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOwEeuQMlH2nbpRWUFnN94Y"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SkvnieY_7sKw","executionInfo":{"status":"ok","timestamp":1729495028265,"user_tz":-480,"elapsed":33996,"user":{"displayName":"Tong Wu","userId":"04187078703020700412"}},"outputId":"210f7e7e-273a-40fb-be0e-210df5546310"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","import tensorflow_decision_forests as tfdf\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.layers import Embedding\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.metrics import classification_report\n","import optuna\n","\n","# 1. Read and preprocess data\n","data_file = '/content/drive/MyDrive/ggg_sg.csv'\n","usecols = ['DocTone', 'ContextualText']\n","data = pd.read_csv(data_file, usecols=usecols)\n","data.dropna(subset=usecols, inplace=True)\n","\n","# 2. Discretize sentiment scores\n","quantiles = data['DocTone'].quantile([0.2, 0.4, 0.6, 0.8]).values\n","\n","def map_sentiment(score):\n","    if score <= quantiles[0]:\n","        return 'Strongly Negative'\n","    elif score <= quantiles[1]:\n","        return 'Negative'\n","    elif score <= quantiles[2]:\n","        return 'Neutral'\n","    elif score <= quantiles[3]:\n","        return 'Positive'\n","    else:\n","        return 'Strongly Positive'\n","\n","data['Sentiment'] = data['DocTone'].apply(map_sentiment)\n","\n","# 3. Encode labels\n","label_encoder = LabelEncoder()\n","data['SentimentLabel'] = label_encoder.fit_transform(data['Sentiment'])\n","\n","# 4. Text tokenization and sequencing\n","texts = data['ContextualText'].astype(str).tolist()\n","tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(texts)\n","sequences = tokenizer.texts_to_sequences(texts)\n","max_sequence_length = 100\n","word_index = tokenizer.word_index\n","data_padded = pad_sequences(sequences, maxlen=max_sequence_length, padding='post')\n","\n","# 5. Create Word2Vec-like embeddings\n","vocab_size = len(word_index) + 1\n","embedding_dim = 100\n","embedding_layer = Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_sequence_length)\n","\n","embedding_matrix = embedding_layer.get_weights()[0]\n","\n","def get_average_embeddings(data_padded, embedding_matrix):\n","    embeddings = []\n","    for sequence in data_padded:\n","        valid_embeddings = [embedding_matrix[idx] for idx in sequence if idx != 0]\n","        if valid_embeddings:\n","            avg_embedding = np.mean(valid_embeddings, axis=0)\n","        else:\n","            avg_embedding = np.zeros(embedding_dim)\n","        embeddings.append(avg_embedding)\n","    return np.array(embeddings)\n","\n","features = get_average_embeddings(data_padded, embedding_matrix)\n","\n","# 6. Split data\n","labels = data['SentimentLabel'].values\n","X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n","\n","# 7. Prepare datasets for TFDF\n","train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(1024)\n","test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(1024)\n","\n","# 8. Hyperparameter tuning using Optuna\n","def objective(trial):\n","    params = {\n","        'num_trees': trial.suggest_int('num_trees', 50, 200),\n","        'max_depth': trial.suggest_int('max_depth', 5, 20),\n","        'min_examples': trial.suggest_int('min_examples', 2, 10),\n","    }\n","    model = tfdf.keras.RandomForestModel(\n","        num_trees=params['num_trees'],\n","        max_depth=params['max_depth'],\n","        min_examples=params['min_examples'],\n","        task=tfdf.keras.Task.CLASSIFICATION\n","    )\n","    model.fit(train_dataset)\n","    evaluation = model.evaluate(test_dataset, return_dict=True)\n","    accuracy = evaluation['accuracy']\n","    return -accuracy\n","\n","study = optuna.create_study()\n","study.optimize(objective, n_trials=10)\n","\n","best_params = study.best_params\n","\n","# 9. Train final model\n","best_params['min_examples'] = max(best_params['min_examples'], 5)  # Increase min_examples\n","final_model = tfdf.keras.RandomForestModel(\n","    num_trees=best_params['num_trees'],\n","    max_depth=best_params['max_depth'],\n","    min_examples=best_params['min_examples'],\n","    task=tfdf.keras.Task.CLASSIFICATION\n",")\n","final_model.fit(train_dataset)\n","\n","# 10. Evaluate model\n","evaluation = final_model.evaluate(test_dataset, return_dict=True)\n","print(\"Test Accuracy:\", evaluation['accuracy'])\n","\n","# Predictions and classification report\n","y_pred = np.argmax(final_model.predict(test_dataset), axis=1)\n","print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n","\n","# 11. Incremental learning (simulated)\n","incremental_model = tfdf.keras.RandomForestModel(\n","    num_trees=50,\n","    max_depth=best_params['max_depth'],\n","    min_examples=best_params['min_examples'],\n","    task=tfdf.keras.Task.CLASSIFICATION\n",")\n","\n","for i in range(5):\n","    print(f\"Training iteration {i+1}\")\n","    incremental_model.fit(train_dataset)\n","    incremental_model.num_trees += 10\n","\n","evaluation = incremental_model.evaluate(test_dataset, return_dict=True)\n","print(\"Incremental Model Test Accuracy:\", evaluation['accuracy'])\n"],"metadata":{"id":"cCAz0Ld-74MD"},"execution_count":null,"outputs":[]}]}