{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN+8UAucZOqCd927pnt0TWN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B3ZkMVn0971A","executionInfo":{"status":"ok","timestamp":1729495724051,"user_tz":-480,"elapsed":2987,"user":{"displayName":"Tong Wu","userId":"04187078703020700412"}},"outputId":"604deefd-d8e0-436f-fcff-98ca41293329"},"outputs":[{"output_type":"stream","name":"stderr","text":["D:\\anaconda3\\envs\\NUS\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import classification_report\n","from sklearn.preprocessing import LabelEncoder\n","from transformers import DebertaTokenizer, TFAutoModel\n","import tensorflow as tf\n","import optuna  # 用于贝叶斯优化"]},{"cell_type":"code","source":["# 假设数据文件位于 'ggg_sg.csv'\n","data_path = \"./Downloads/ggg_sg.csv\"\n","\n","# 获取文件的总行数（可选，如果文件过大，可跳过此步骤）\n","# total_rows = sum(1 for line in open(data_path, 'r', encoding='utf-8')) - 1  # 减去标题行\n","\n","# 计算需要读取的行数（三分之一）\n","# one_third_rows = total_rows // 3\n","\n","# 使用 Pandas 读取 CSV 文件的三分之一\n","# 如果 total_rows 已知，可以使用 nrows 参数\n","# df = pd.read_csv(data_path, nrows=one_third_rows)\n","\n","# 如果 total_rows 未知，直接随机采样读取部分数据\n","df = pd.read_csv(data_path, usecols=['DateTime', 'Title', 'DomainCountryCode', 'ContextualText', 'DocTone'])\n","\n","# 随机采样三分之一的数据\n","df_sampled = df#.sample(frac=0.33, random_state=42).reset_index(drop=True)\n"],"metadata":{"id":"rvetLjpP9-eP","executionInfo":{"status":"ok","timestamp":1729495792333,"user_tz":-480,"elapsed":66130,"user":{"displayName":"Tong Wu","userId":"04187078703020700412"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# 确保 'ContextualText' 和 'DocTone' 列存在\n","df_filtered = df_sampled[['ContextualText', 'DocTone']].dropna(subset=['ContextualText', 'DocTone'])\n","\n","# 将 'DocTone' 列转换为浮点型\n","df_filtered['DocTone'] = df_filtered['DocTone'].astype(float)\n","\n","# 定义百分位数列表\n","percentiles = [0.2, 0.4, 0.6, 0.8]\n","\n","# 计算百分位数\n","quantiles = df_filtered['DocTone'].quantile(percentiles).values\n","\n","# 输出百分位数阈值\n","print(\"DocTone percentile threshold：\", quantiles)\n","\n","# 获取阈值\n","q1, q2, q3, q4 = quantiles\n","\n","def label_sentiment(score):\n","    if score <= q1:\n","        return 'Strongly Negative'  # 强烈负面\n","    elif q1 < score <= q2:\n","        return 'Negative'  # 负面\n","    elif q2 < score <= q3:\n","        return 'Neutral'  # 中性\n","    elif q3 < score <= q4:\n","        return 'Positive'  # 正面\n","    else:\n","        return 'Strongly Positive'  # 强烈正面\n","\n","# 应用标签函数\n","data = df_filtered.copy()\n","data['Sentiment'] = data['DocTone'].apply(label_sentiment)\n","\n","# 标签编码\n","label_encoder = LabelEncoder()\n","data['SentimentLabel'] = label_encoder.fit_transform(data['Sentiment'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CNyhBbA9-Af2","executionInfo":{"status":"ok","timestamp":1729495796446,"user_tz":-480,"elapsed":4067,"user":{"displayName":"Tong Wu","userId":"04187078703020700412"}},"outputId":"a37b03d5-2130-4271-cab2-c46879565324"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["DocTone percentile threshold： [-2.58706468 -0.65502183  0.79928952  2.47191011]\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","import tensorflow_decision_forests as tfdf\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.layers import Embedding\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","import keras_tuner as kt\n","import optuna\n","\n","# Extract texts\n","texts = data['ContextualText'].astype(str).tolist()\n","\n","# Initialize the tokenizer\n","tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(texts)\n","\n","# Convert texts to sequences\n","sequences = tokenizer.texts_to_sequences(texts)\n","\n","# Pad sequences to the same length\n","max_sequence_length = 100  # You can adjust this value\n","word_index = tokenizer.word_index\n","data_padded = pad_sequences(sequences, maxlen=max_sequence_length, padding='post')\n","\n","# Vocabulary size\n","vocab_size = len(word_index) + 1  # Adding 1 because of reserved 0 index\n","\n","# Embedding dimension\n","embedding_dim = 100  # You can adjust this value\n","\n","# Define the embedding layer\n","embedding_layer = Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_sequence_length)\n","\n","# Get the embedding weights (randomly initialized)\n","embedding_matrix = embedding_layer.get_weights()[0]\n","\n","# Function to compute average embeddings\n","def get_average_embeddings(data_padded, embedding_matrix):\n","    embeddings = []\n","    for sequence in data_padded:\n","        valid_embeddings = [embedding_matrix[idx] for idx in sequence if idx != 0]\n","        if valid_embeddings:\n","            avg_embedding = np.mean(valid_embeddings, axis=0)\n","        else:\n","            avg_embedding = np.zeros(embedding_dim)\n","        embeddings.append(avg_embedding)\n","    return np.array(embeddings)\n","\n","# Compute average embeddings for all texts\n","features = get_average_embeddings(data_padded, embedding_matrix)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"EdX4A_Mx-GwG","executionInfo":{"status":"error","timestamp":1729495862107,"user_tz":-480,"elapsed":2923,"user":{"displayName":"Tong Wu","userId":"04187078703020700412"}},"outputId":"40b1cf33-1f55-481e-ebb7-6955b065ab69"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:root:TensorFlow Decision Forests 1.8.1 is compatible with the following TensorFlow Versions: ['2.15.0']. However, TensorFlow 2.17.0 was detected. This can cause issues with the TF API and symbols in the custom C++ ops. See the TF and TF-DF compatibility table at https://github.com/tensorflow/decision-forests/blob/main/documentation/known_issues.md#compatibility-table.\n","WARNING:root:Failure to load the inference.so custom c++ tensorflow ops. This error is likely caused the version of TensorFlow and TensorFlow Decision Forests are not compatible. Full error:D:\\anaconda3\\envs\\NUS\\lib\\site-packages\\tensorflow_decision_forests\\tensorflow\\ops\\inference\\inference.so not found\n"]},{"output_type":"error","ename":"NotFoundError","evalue":"D:\\anaconda3\\envs\\NUS\\lib\\site-packages\\tensorflow_decision_forests\\tensorflow\\ops\\inference\\inference.so not found","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)","Cell \u001b[1;32mIn[6], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow_decision_forests\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtfdf\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tokenizer\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msequence\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pad_sequences\n","File \u001b[1;32mD:\\anaconda3\\envs\\NUS\\lib\\site-packages\\tensorflow_decision_forests\\__init__.py:64\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_decision_forests\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_version\n\u001b[0;32m     62\u001b[0m check_version\u001b[38;5;241m.\u001b[39mcheck_version(__version__, compatible_tf_versions)\n\u001b[1;32m---> 64\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_decision_forests\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_decision_forests\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomponent\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m py_tree\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_decision_forests\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomponent\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbuilder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m builder\n","File \u001b[1;32mD:\\anaconda3\\envs\\NUS\\lib\\site-packages\\tensorflow_decision_forests\\keras\\__init__.py:53\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Decision Forest in a Keras Model.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03mUsage example:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;124;03m```\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Callable, List\n\u001b[1;32m---> 53\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_decision_forests\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m core\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_decision_forests\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m wrappers\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# Utility classes\u001b[39;00m\n","File \u001b[1;32mD:\\anaconda3\\envs\\NUS\\lib\\site-packages\\tensorflow_decision_forests\\keras\\core.py:62\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_decision_forests\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomponent\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minspector\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m inspector \u001b[38;5;28;01mas\u001b[39;00m inspector_lib\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_decision_forests\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomponent\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtuner\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tuner \u001b[38;5;28;01mas\u001b[39;00m tuner_lib\n\u001b[1;32m---> 62\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_decision_forests\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m core_inference\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_decision_forests\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cc_logging\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_decision_forests\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m core \u001b[38;5;28;01mas\u001b[39;00m tf_core\n","File \u001b[1;32mD:\\anaconda3\\envs\\NUS\\lib\\site-packages\\tensorflow_decision_forests\\keras\\core_inference.py:36\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_decision_forests\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m core_inference \u001b[38;5;28;01mas\u001b[39;00m tf_core\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_decision_forests\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf_logging\n\u001b[1;32m---> 36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_decision_forests\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minference\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m api \u001b[38;5;28;01mas\u001b[39;00m tf_op\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01myggdrasil_decision_forests\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlearner\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m abstract_learner_pb2\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01myggdrasil_decision_forests\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlearner\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmultitasker\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m multitasker_pb2\n","File \u001b[1;32mD:\\anaconda3\\envs\\NUS\\lib\\site-packages\\tensorflow_decision_forests\\tensorflow\\ops\\inference\\api.py:179\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_decision_forests\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomponent\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minspector\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m inspector \u001b[38;5;28;01mas\u001b[39;00m inspector_lib\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_decision_forests\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf1_compatibility\n\u001b[1;32m--> 179\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_decision_forests\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minference\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m op\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01myggdrasil_decision_forests\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m data_spec_pb2\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01myggdrasil_decision_forests\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m abstract_model_pb2\n","File \u001b[1;32mD:\\anaconda3\\envs\\NUS\\lib\\site-packages\\tensorflow_decision_forests\\tensorflow\\ops\\inference\\op.py:15\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2021 Google LLC.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_decision_forests\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minference\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mop_dynamic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n","File \u001b[1;32mD:\\anaconda3\\envs\\NUS\\lib\\site-packages\\tensorflow_decision_forests\\tensorflow\\ops\\inference\\op_dynamic.py:24\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     23\u001b[0m   check_version\u001b[38;5;241m.\u001b[39minfo_fail_to_load_custom_op(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minference.so\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 24\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Importing all the symbols.\u001b[39;00m\n\u001b[0;32m     27\u001b[0m module \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mmodules[\u001b[38;5;18m__name__\u001b[39m]\n","File \u001b[1;32mD:\\anaconda3\\envs\\NUS\\lib\\site-packages\\tensorflow_decision_forests\\tensorflow\\ops\\inference\\op_dynamic.py:21\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 21\u001b[0m   ops \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_op_library\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresource_loader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_path_to_datafile\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minference.so\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     23\u001b[0m   check_version\u001b[38;5;241m.\u001b[39minfo_fail_to_load_custom_op(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minference.so\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[1;32mD:\\anaconda3\\envs\\NUS\\lib\\site-packages\\tensorflow\\python\\framework\\load_library.py:54\u001b[0m, in \u001b[0;36mload_op_library\u001b[1;34m(library_filename)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mload_op_library\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_op_library\u001b[39m(library_filename):\n\u001b[0;32m     33\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Loads a TensorFlow plugin, containing custom ops and kernels.\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \n\u001b[0;32m     35\u001b[0m \u001b[38;5;124;03m  Pass \"library_filename\" to a platform-specific mechanism for dynamically\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;124;03m    RuntimeError: when unable to load the library or get the python wrappers.\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m---> 54\u001b[0m   lib_handle \u001b[38;5;241m=\u001b[39m \u001b[43mpy_tf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTF_LoadLibrary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlibrary_filename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     56\u001b[0m     wrappers \u001b[38;5;241m=\u001b[39m _pywrap_python_op_gen\u001b[38;5;241m.\u001b[39mGetPythonWrappers(\n\u001b[0;32m     57\u001b[0m         py_tf\u001b[38;5;241m.\u001b[39mTF_GetOpList(lib_handle))\n","\u001b[1;31mNotFoundError\u001b[0m: D:\\anaconda3\\envs\\NUS\\lib\\site-packages\\tensorflow_decision_forests\\tensorflow\\ops\\inference\\inference.so not found"]}]},{"cell_type":"code","source":["from sklearn.model_selection import RandomizedSearchCV\n","from scipy.stats import randint\n","\n","# 定义参数分布\n","param_dist = {\n","    'n_estimators': randint(50, 200),\n","    'max_depth': randint(5, 50),\n","    'min_samples_leaf': randint(1, 10),\n","    'min_samples_split': randint(2, 15),\n","    'max_features': ['auto', 'sqrt', 'log2']\n","}\n","\n","# 定义随机森林分类器\n","rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n","\n","# 定义随机搜索\n","n_iter_search = 20  # 搜索次数\n","random_search = RandomizedSearchCV(rf, param_distributions=param_dist, n_iter=n_iter_search, cv=3, scoring='accuracy', random_state=42)\n","\n","# Create a custom tqdm callback\n","class TQDMProgressBar(tqdm):\n","    def __init__(self, total=None, **kwargs):\n","        super().__init__(total=total, **kwargs)\n","        self.total = total\n","\n","    def __call__(self, *args, **kwargs):\n","        self.update(1)\n","\n","# Initialize the progress bar\n","progress_bar = TQDMProgressBar(total=n_iter_search)\n","\n","# Perform the hyperparameter tuning with progress tracking\n","random_search = RandomizedSearchCV(\n","    rf,\n","    param_distributions=param_dist,\n","    n_iter=n_iter_search,\n","    cv=3,\n","    scoring='accuracy',\n","    random_state=42,\n","    verbose=0,\n",")\n","\n","# Wrap the fit method to use the progress bar\n","for _ in range(n_iter_search):\n","    progress_bar.__call__()\n","    random_search.fit(X_train, y_train)\n","\n","# Close the progress bar\n","progress_bar.close()\n","\n","# Output the best parameters\n","print(\"Best parameters found by random search:\")\n","print(random_search.best_params_)"],"metadata":{"id":"wUd1QsqA-2w3"},"execution_count":null,"outputs":[]}]}