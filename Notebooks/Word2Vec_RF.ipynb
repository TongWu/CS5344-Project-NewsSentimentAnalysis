{"cells":[{"cell_type":"code","source":["!wget https://repo1.maven.org/maven2/com/nvidia/rapids-4-spark_2.13/24.08.1/rapids-4-spark_2.13-24.08.1-cuda12.jar"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PPpnW0u8h5af","executionInfo":{"status":"ok","timestamp":1727425003762,"user_tz":-480,"elapsed":48238,"user":{"displayName":"Tong Wu","userId":"04187078703020700412"}},"outputId":"d50fe22c-cdbd-4e1c-aa9c-687904e01ad8"},"id":"PPpnW0u8h5af","execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["--2024-09-27 16:15:55--  https://repo1.maven.org/maven2/com/nvidia/rapids-4-spark_2.13/24.08.1/rapids-4-spark_2.13-24.08.1-cuda12.jar\r\n","Resolving repo1.maven.org (repo1.maven.org)... 146.75.92.209, 2a04:4e42:7a::209\n","Connecting to repo1.maven.org (repo1.maven.org)|146.75.92.209|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 500547780 (477M) [application/java-archive]\n","Saving to: ‘rapids-4-spark_2.13-24.08.1-cuda12.jar’\n","\n","k_2.13-24.08.1-cuda  70%[=============>      ] 336.47M  21.6MB/s    eta 7s     "]},{"output_type":"stream","name":"stderr","text":["\r[Stage 5:>                                                          (0 + 1) / 1]\r"]},{"output_type":"stream","name":"stdout","text":["rapids-4-spark_2.13 100%[===================>] 477.36M  21.5MB/s    in 23s     \n","\n","2024-09-27 16:16:43 (20.4 MB/s) - ‘rapids-4-spark_2.13-24.08.1-cuda12.jar’ saved [500547780/500547780]\n","\n"]}]},{"metadata":{"jupyter":{"is_executing":true},"ExecuteTime":{"start_time":"2024-09-27T06:39:32.839246Z"},"id":"5359eaed83bf92ba"},"cell_type":"code","source":["from pyspark.sql import SparkSession\n","from pyspark.sql.functions import col, udf, when, isnan, isnull\n","from pyspark.sql.types import IntegerType, StringType, FloatType\n","from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF, StringIndexer\n","from pyspark.ml.classification import LogisticRegression\n","from pyspark.ml import Pipeline\n","from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n","from pyspark.ml.feature import Word2Vec\n","from pyspark.ml.classification import RandomForestClassifier\n","\n","spark = SparkSession.builder.appName(\n","            \"SentimentAnalysisBaseline\"\n","        ).config(\n","            \"spark.executor.memory\", \"16g\"\n","        ).config(\n","            \"spark.driver.memory\", \"32g\"\n","        ).config(\n","            \"spark.executor.extraClassPath\", \"rapids-4-spark_2.13-24.08.1-cuda12.jar\"\n","        ).config(\n","            \"spark.driver.extraClassPath\", \"rapids-4-spark_2.13-24.08.1-cuda12.jar\"\n","        ).getOrCreate()\n","\n","df = spark.read.csv(\"./ggg_sg.csv\", header=True, inferSchema=True, multiLine=True, escape='\"')\n","df = df.filter(df.ContextualText.isNotNull())\n","df = df.filter(df.DocTone.isNotNull())\n","df = df.withColumn(\"DocTone\", df[\"DocTone\"].cast(FloatType()))\n","# Create sentiment label: Positive (2), Neutral (1), Negative (0)\n","def sentiment_label(score):\n","    if score > 1.9910:\n","        return 2\n","    elif score < -2.0202:\n","        return 0\n","    else:\n","        return 1\n","\n","sentiment_udf = udf(sentiment_label, IntegerType())\n","\n","df = df.withColumn(\"label\", sentiment_udf(col(\"DocTone\")))\n","tokenizer = Tokenizer(inputCol=\"ContextualText\", outputCol=\"words\")\n","remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered_words\")\n","# Feature extraction (Word2Vec)\n","word2Vec = Word2Vec(vectorSize=100, minCount=5, inputCol=\"filtered_words\", outputCol=\"features\")\n","\n","pipeline = Pipeline(stages=[tokenizer, remover, word2Vec])\n","(trainingData, testData) = df.randomSplit([0.8, 0.2], seed=42)\n","\n","pipelineModel = pipeline.fit(trainingData)\n","trainingData = pipelineModel.transform(trainingData)\n","testData = pipelineModel.transform(testData)\n","\n","# Random Forest model\n","rf = RandomForestClassifier(featuresCol='features', labelCol='label', numTrees=50, maxDepth=10, seed=42)\n","\n","rfModel = rf.fit(trainingData)"],"id":"5359eaed83bf92ba","outputs":[],"execution_count":null},{"cell_type":"code","source":["df = df.filter(df.ContextualText.isNotNull())\n","df = df.filter(df.DocTone.isNotNull())\n","df = df.withColumn(\"DocTone\", df[\"DocTone\"].cast(FloatType()))\n","# Create sentiment label: Positive (2), Neutral (1), Negative (0)\n","def sentiment_label(score):\n","    if score > 1.9910:\n","        return 2\n","    elif score < -2.0202:\n","        return 0\n","    else:\n","        return 1\n","\n","sentiment_udf = udf(sentiment_label, IntegerType())\n","\n","df = df.withColumn(\"label\", sentiment_udf(col(\"DocTone\")))\n","tokenizer = Tokenizer(inputCol=\"ContextualText\", outputCol=\"words\")\n","remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered_words\")\n","# Feature extraction (Word2Vec)\n","word2Vec = Word2Vec(vectorSize=100, minCount=5, inputCol=\"filtered_words\", outputCol=\"features\")\n","\n","pipeline = Pipeline(stages=[tokenizer, remover, word2Vec])\n","(trainingData, testData) = df.randomSplit([0.8, 0.2], seed=42)\n","\n","pipelineModel = pipeline.fit(trainingData)\n","trainingData = pipelineModel.transform(trainingData)\n","testData = pipelineModel.transform(testData)\n","\n","# Random Forest model\n","rf = RandomForestClassifier(featuresCol='features', labelCol='label', numTrees=50, maxDepth=10, seed=42)\n","\n","rfModel = rf.fit(trainingData)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"igFHYOmAleme","executionInfo":{"status":"ok","timestamp":1727436983746,"user_tz":-480,"elapsed":11433756,"user":{"displayName":"Tong Wu","userId":"04187078703020700412"}},"outputId":"15743a59-7e30-4497-b12f-06b45de57624"},"id":"igFHYOmAleme","execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["24/09/27 18:31:50 ERROR TaskContextImpl: Error in TaskCompletionListener\n","org.apache.spark.SparkException: Block broadcast_6 does not exist\n","\tat org.apache.spark.errors.SparkCoreErrors$.blockDoesNotExistError(SparkCoreErrors.scala:318)\n","\tat org.apache.spark.storage.BlockInfoManager.blockInfo(BlockInfoManager.scala:269)\n","\tat org.apache.spark.storage.BlockInfoManager.unlock(BlockInfoManager.scala:390)\n","\tat org.apache.spark.storage.BlockManager.releaseLock(BlockManager.scala:1309)\n","\tat org.apache.spark.broadcast.TorrentBroadcast.$anonfun$releaseBlockManagerLock$1(TorrentBroadcast.scala:319)\n","\tat org.apache.spark.broadcast.TorrentBroadcast.$anonfun$releaseBlockManagerLock$1$adapted(TorrentBroadcast.scala:319)\n","\tat org.apache.spark.TaskContext$$anon$1.onTaskCompletion(TaskContext.scala:137)\n","\tat org.apache.spark.TaskContextImpl.$anonfun$invokeTaskCompletionListeners$1(TaskContextImpl.scala:144)\n","\tat org.apache.spark.TaskContextImpl.$anonfun$invokeTaskCompletionListeners$1$adapted(TaskContextImpl.scala:144)\n","\tat org.apache.spark.TaskContextImpl.invokeListeners(TaskContextImpl.scala:199)\n","\tat org.apache.spark.TaskContextImpl.invokeTaskCompletionListeners(TaskContextImpl.scala:144)\n","\tat org.apache.spark.TaskContextImpl.markTaskCompleted(TaskContextImpl.scala:137)\n","\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:177)\n","\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n","\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n","\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n","\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n","\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n","\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n","\tat java.base/java.lang.Thread.run(Thread.java:1570)\n","24/09/27 18:31:50 ERROR TaskContextImpl: Error in TaskCompletionListener\n","org.apache.spark.SparkException: Block broadcast_7 does not exist\n","\tat org.apache.spark.errors.SparkCoreErrors$.blockDoesNotExistError(SparkCoreErrors.scala:318)\n","\tat org.apache.spark.storage.BlockInfoManager.blockInfo(BlockInfoManager.scala:269)\n","\tat org.apache.spark.storage.BlockInfoManager.unlock(BlockInfoManager.scala:390)\n","\tat org.apache.spark.storage.BlockManager.releaseLock(BlockManager.scala:1309)\n","\tat org.apache.spark.broadcast.TorrentBroadcast.$anonfun$releaseBlockManagerLock$1(TorrentBroadcast.scala:319)\n","\tat org.apache.spark.broadcast.TorrentBroadcast.$anonfun$releaseBlockManagerLock$1$adapted(TorrentBroadcast.scala:319)\n","\tat org.apache.spark.TaskContext$$anon$1.onTaskCompletion(TaskContext.scala:137)\n","\tat org.apache.spark.TaskContextImpl.$anonfun$invokeTaskCompletionListeners$1(TaskContextImpl.scala:144)\n","\tat org.apache.spark.TaskContextImpl.$anonfun$invokeTaskCompletionListeners$1$adapted(TaskContextImpl.scala:144)\n","\tat org.apache.spark.TaskContextImpl.invokeListeners(TaskContextImpl.scala:199)\n","\tat org.apache.spark.TaskContextImpl.invokeTaskCompletionListeners(TaskContextImpl.scala:144)\n","\tat org.apache.spark.TaskContextImpl.markTaskCompleted(TaskContextImpl.scala:137)\n","\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:177)\n","\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n","\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n","\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n","\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n","\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n","\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n","\tat java.base/java.lang.Thread.run(Thread.java:1570)\n","24/09/27 18:31:50 ERROR TaskContextImpl: Error in TaskCompletionListener\n","org.apache.spark.SparkException: Block broadcast_10 does not exist\n","\tat org.apache.spark.errors.SparkCoreErrors$.blockDoesNotExistError(SparkCoreErrors.scala:318)\n","\tat org.apache.spark.storage.BlockInfoManager.blockInfo(BlockInfoManager.scala:269)\n","\tat org.apache.spark.storage.BlockInfoManager.unlock(BlockInfoManager.scala:390)\n","\tat org.apache.spark.storage.BlockManager.releaseLock(BlockManager.scala:1309)\n","\tat org.apache.spark.broadcast.TorrentBroadcast.$anonfun$releaseBlockManagerLock$1(TorrentBroadcast.scala:319)\n","\tat org.apache.spark.broadcast.TorrentBroadcast.$anonfun$releaseBlockManagerLock$1$adapted(TorrentBroadcast.scala:319)\n","\tat org.apache.spark.TaskContext$$anon$1.onTaskCompletion(TaskContext.scala:137)\n","\tat org.apache.spark.TaskContextImpl.$anonfun$invokeTaskCompletionListeners$1(TaskContextImpl.scala:144)\n","\tat org.apache.spark.TaskContextImpl.$anonfun$invokeTaskCompletionListeners$1$adapted(TaskContextImpl.scala:144)\n","\tat org.apache.spark.TaskContextImpl.invokeListeners(TaskContextImpl.scala:199)\n","\tat org.apache.spark.TaskContextImpl.invokeTaskCompletionListeners(TaskContextImpl.scala:144)\n","\tat org.apache.spark.TaskContextImpl.markTaskCompleted(TaskContextImpl.scala:137)\n","\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:177)\n","\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n","\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n","\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n","\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n","\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n","\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n","\tat java.base/java.lang.Thread.run(Thread.java:1570)\n","24/09/27 18:31:50 ERROR TaskContextImpl: Error in TaskCompletionListener\n","org.apache.spark.SparkException: Block broadcast_9 does not exist\n","\tat org.apache.spark.errors.SparkCoreErrors$.blockDoesNotExistError(SparkCoreErrors.scala:318)\n","\tat org.apache.spark.storage.BlockInfoManager.blockInfo(BlockInfoManager.scala:269)\n","\tat org.apache.spark.storage.BlockInfoManager.unlock(BlockInfoManager.scala:390)\n","\tat org.apache.spark.storage.BlockManager.releaseLock(BlockManager.scala:1309)\n","\tat org.apache.spark.broadcast.TorrentBroadcast.$anonfun$releaseBlockManagerLock$1(TorrentBroadcast.scala:319)\n","\tat org.apache.spark.broadcast.TorrentBroadcast.$anonfun$releaseBlockManagerLock$1$adapted(TorrentBroadcast.scala:319)\n","\tat org.apache.spark.TaskContext$$anon$1.onTaskCompletion(TaskContext.scala:137)\n","\tat org.apache.spark.TaskContextImpl.$anonfun$invokeTaskCompletionListeners$1(TaskContextImpl.scala:144)\n","\tat org.apache.spark.TaskContextImpl.$anonfun$invokeTaskCompletionListeners$1$adapted(TaskContextImpl.scala:144)\n","\tat org.apache.spark.TaskContextImpl.invokeListeners(TaskContextImpl.scala:199)\n","\tat org.apache.spark.TaskContextImpl.invokeTaskCompletionListeners(TaskContextImpl.scala:144)\n","\tat org.apache.spark.TaskContextImpl.markTaskCompleted(TaskContextImpl.scala:137)\n","\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:177)\n","\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n","\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n","\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n","\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n","\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n","\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n","\tat java.base/java.lang.Thread.run(Thread.java:1570)\n","24/09/27 18:31:50 ERROR TaskContextImpl: Error in TaskCompletionListener\n","org.apache.spark.SparkException: Block broadcast_12 does not exist\n","\tat org.apache.spark.errors.SparkCoreErrors$.blockDoesNotExistError(SparkCoreErrors.scala:318)\n","\tat org.apache.spark.storage.BlockInfoManager.blockInfo(BlockInfoManager.scala:269)\n","\tat org.apache.spark.storage.BlockInfoManager.unlock(BlockInfoManager.scala:390)\n","\tat org.apache.spark.storage.BlockManager.releaseLock(BlockManager.scala:1309)\n","\tat org.apache.spark.broadcast.TorrentBroadcast.$anonfun$releaseBlockManagerLock$1(TorrentBroadcast.scala:319)\n","\tat org.apache.spark.broadcast.TorrentBroadcast.$anonfun$releaseBlockManagerLock$1$adapted(TorrentBroadcast.scala:319)\n","\tat org.apache.spark.TaskContext$$anon$1.onTaskCompletion(TaskContext.scala:137)\n","\tat org.apache.spark.TaskContextImpl.$anonfun$invokeTaskCompletionListeners$1(TaskContextImpl.scala:144)\n","\tat org.apache.spark.TaskContextImpl.$anonfun$invokeTaskCompletionListeners$1$adapted(TaskContextImpl.scala:144)\n","\tat org.apache.spark.TaskContextImpl.invokeListeners(TaskContextImpl.scala:199)\n","\tat org.apache.spark.TaskContextImpl.invokeTaskCompletionListeners(TaskContextImpl.scala:144)\n","\tat org.apache.spark.TaskContextImpl.markTaskCompleted(TaskContextImpl.scala:137)\n","\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:177)\n","\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n","\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n","\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n","\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n","\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n","\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n","\tat java.base/java.lang.Thread.run(Thread.java:1570)\n","24/09/27 18:31:50 ERROR Executor: Exception in task 0.0 in stage 5.0 (TID 5): Block rdd_23_0 does not exist\n","24/09/27 19:23:25 WARN DAGScheduler: Broadcasting large task binary with size 1178.2 KiB\n","24/09/27 19:25:31 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n","24/09/27 19:28:01 WARN DAGScheduler: Broadcasting large task binary with size 4.3 MiB\n","24/09/27 19:31:17 WARN DAGScheduler: Broadcasting large task binary with size 1241.4 KiB\n","24/09/27 19:31:18 WARN DAGScheduler: Broadcasting large task binary with size 8.3 MiB\n","24/09/27 19:36:21 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n"]}]},{"metadata":{"id":"cb4601f191f29f12"},"cell_type":"code","outputs":[],"execution_count":null,"source":["predictions = rfModel.transform(testData)\n","# Evaluate model\n","evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n","accuracy = evaluator.evaluate(predictions)\n","print(\"Test Accuracy = %g \" % accuracy)\n","\n","# Detailed evaluation\n","evaluator_precision = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedPrecision\")\n","precision = evaluator_precision.evaluate(predictions)\n","\n","evaluator_recall = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\n","recall = evaluator_recall.evaluate(predictions)\n","\n","evaluator_f1 = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n","f1 = evaluator_f1.evaluate(predictions)\n","\n","print(f\"Precision: {precision}\")\n","print(f\"Recall: {recall}\")\n","print(f\"F1 Score: {f1}\")\n","\n","predictions.select(\"ContextualText\", \"label\", \"prediction\").show(10, truncate=50)"],"id":"cb4601f191f29f12"},{"metadata":{"id":"356b793922b9c18"},"cell_type":"code","outputs":[],"execution_count":null,"source":[],"id":"356b793922b9c18"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.6"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}