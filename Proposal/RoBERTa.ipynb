{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "496973ad8551a7e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T04:37:49.014091Z",
     "start_time": "2024-09-27T04:37:08.514200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/tedwu/anaconda3/envs/CS5344/lib/python3.11/site-packages/tensorflow\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb07ff4dc2985d0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T04:28:57.007495Z",
     "start_time": "2024-09-27T04:28:57.005608Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.1.2\n"
     ]
    }
   ],
   "source": [
    "import sparknlp\n",
    "print(sparknlp.version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T04:30:50.506412Z",
     "start_time": "2024-09-27T04:29:36.856735Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/Users/tedwu/anaconda3/envs/CS5344/lib/python3.11/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /Users/tedwu/.ivy2/cache\n",
      "The jars for the packages stored in: /Users/tedwu/.ivy2/jars\n",
      "com.johnsnowlabs.nlp#spark-nlp_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-0fbf36a2-6aae-4f83-90e3-d3e61342df2e;1.0\n",
      "\tconfs: [default]\n",
      "\tfound com.johnsnowlabs.nlp#spark-nlp_2.12;4.2.0 in central\n",
      "\tfound com.typesafe#config;1.4.2 in central\n",
      "\tfound org.rocksdb#rocksdbjni;6.29.5 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-bundle;1.11.828 in central\n",
      "\tfound com.github.universal-automata#liblevenshtein;3.0.0 in central\n",
      "\tfound com.google.code.findbugs#annotations;3.0.1 in central\n",
      "\tfound net.jcip#jcip-annotations;1.0 in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.1 in central\n",
      "\tfound com.google.protobuf#protobuf-java-util;3.0.0-beta-3 in central\n",
      "\tfound com.google.protobuf#protobuf-java;3.0.0-beta-3 in central\n",
      "\tfound com.google.code.gson#gson;2.3 in central\n",
      "\tfound it.unimi.dsi#fastutil;7.0.12 in central\n",
      "\tfound org.projectlombok#lombok;1.16.8 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.21 in local-m2-cache\n",
      "\tfound com.navigamez#greex;1.0 in central\n",
      "\tfound dk.brics.automaton#automaton;1.11-8 in central\n",
      "\tfound com.johnsnowlabs.nlp#tensorflow-cpu_2.12;0.4.3 in central\n",
      "downloading https://repo1.maven.org/maven2/com/johnsnowlabs/nlp/spark-nlp_2.12/4.2.0/spark-nlp_2.12-4.2.0.jar ...\n",
      "\t[SUCCESSFUL ] com.johnsnowlabs.nlp#spark-nlp_2.12;4.2.0!spark-nlp_2.12.jar (4071ms)\n",
      "downloading https://repo1.maven.org/maven2/com/typesafe/config/1.4.2/config-1.4.2.jar ...\n",
      "\t[SUCCESSFUL ] com.typesafe#config;1.4.2!config.jar(bundle) (378ms)\n",
      "downloading https://repo1.maven.org/maven2/org/rocksdb/rocksdbjni/6.29.5/rocksdbjni-6.29.5.jar ...\n",
      "\t[SUCCESSFUL ] org.rocksdb#rocksdbjni;6.29.5!rocksdbjni.jar (2735ms)\n",
      "downloading https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk-bundle/1.11.828/aws-java-sdk-bundle-1.11.828.jar ...\n",
      "\t[SUCCESSFUL ] com.amazonaws#aws-java-sdk-bundle;1.11.828!aws-java-sdk-bundle.jar (16477ms)\n",
      "downloading https://repo1.maven.org/maven2/com/github/universal-automata/liblevenshtein/3.0.0/liblevenshtein-3.0.0.jar ...\n",
      "\t[SUCCESSFUL ] com.github.universal-automata#liblevenshtein;3.0.0!liblevenshtein.jar (431ms)\n",
      "downloading https://repo1.maven.org/maven2/com/navigamez/greex/1.0/greex-1.0.jar ...\n",
      "\t[SUCCESSFUL ] com.navigamez#greex;1.0!greex.jar (372ms)\n",
      "downloading https://repo1.maven.org/maven2/com/johnsnowlabs/nlp/tensorflow-cpu_2.12/0.4.3/tensorflow-cpu_2.12-0.4.3.jar ...\n",
      "\t[SUCCESSFUL ] com.johnsnowlabs.nlp#tensorflow-cpu_2.12;0.4.3!tensorflow-cpu_2.12.jar (26755ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/code/findbugs/annotations/3.0.1/annotations-3.0.1.jar ...\n",
      "\t[SUCCESSFUL ] com.google.code.findbugs#annotations;3.0.1!annotations.jar (373ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/protobuf/protobuf-java-util/3.0.0-beta-3/protobuf-java-util-3.0.0-beta-3.jar ...\n",
      "\t[SUCCESSFUL ] com.google.protobuf#protobuf-java-util;3.0.0-beta-3!protobuf-java-util.jar(bundle) (375ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/protobuf/protobuf-java/3.0.0-beta-3/protobuf-java-3.0.0-beta-3.jar ...\n",
      "\t[SUCCESSFUL ] com.google.protobuf#protobuf-java;3.0.0-beta-3!protobuf-java.jar(bundle) (418ms)\n",
      "downloading https://repo1.maven.org/maven2/it/unimi/dsi/fastutil/7.0.12/fastutil-7.0.12.jar ...\n",
      "\t[SUCCESSFUL ] it.unimi.dsi#fastutil;7.0.12!fastutil.jar (1155ms)\n",
      "downloading https://repo1.maven.org/maven2/org/projectlombok/lombok/1.16.8/lombok-1.16.8.jar ...\n",
      "\t[SUCCESSFUL ] org.projectlombok#lombok;1.16.8!lombok.jar (423ms)\n",
      "downloading file:/Users/tedwu/.m2/repository/org/slf4j/slf4j-api/1.7.21/slf4j-api-1.7.21.jar ...\n",
      "\t[SUCCESSFUL ] org.slf4j#slf4j-api;1.7.21!slf4j-api.jar (2ms)\n",
      "downloading https://repo1.maven.org/maven2/net/jcip/jcip-annotations/1.0/jcip-annotations-1.0.jar ...\n",
      "\t[SUCCESSFUL ] net.jcip#jcip-annotations;1.0!jcip-annotations.jar (372ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/code/findbugs/jsr305/3.0.1/jsr305-3.0.1.jar ...\n",
      "\t[SUCCESSFUL ] com.google.code.findbugs#jsr305;3.0.1!jsr305.jar (373ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/code/gson/gson/2.3/gson-2.3.jar ...\n",
      "\t[SUCCESSFUL ] com.google.code.gson#gson;2.3!gson.jar (380ms)\n",
      "downloading https://repo1.maven.org/maven2/dk/brics/automaton/automaton/1.11-8/automaton-1.11-8.jar ...\n",
      "\t[SUCCESSFUL ] dk.brics.automaton#automaton;1.11-8!automaton.jar (432ms)\n",
      ":: resolution report :: resolve 13447ms :: artifacts dl 55534ms\n",
      "\t:: modules in use:\n",
      "\tcom.amazonaws#aws-java-sdk-bundle;1.11.828 from central in [default]\n",
      "\tcom.github.universal-automata#liblevenshtein;3.0.0 from central in [default]\n",
      "\tcom.google.code.findbugs#annotations;3.0.1 from central in [default]\n",
      "\tcom.google.code.findbugs#jsr305;3.0.1 from central in [default]\n",
      "\tcom.google.code.gson#gson;2.3 from central in [default]\n",
      "\tcom.google.protobuf#protobuf-java;3.0.0-beta-3 from central in [default]\n",
      "\tcom.google.protobuf#protobuf-java-util;3.0.0-beta-3 from central in [default]\n",
      "\tcom.johnsnowlabs.nlp#spark-nlp_2.12;4.2.0 from central in [default]\n",
      "\tcom.johnsnowlabs.nlp#tensorflow-cpu_2.12;0.4.3 from central in [default]\n",
      "\tcom.navigamez#greex;1.0 from central in [default]\n",
      "\tcom.typesafe#config;1.4.2 from central in [default]\n",
      "\tdk.brics.automaton#automaton;1.11-8 from central in [default]\n",
      "\tit.unimi.dsi#fastutil;7.0.12 from central in [default]\n",
      "\tnet.jcip#jcip-annotations;1.0 from central in [default]\n",
      "\torg.projectlombok#lombok;1.16.8 from central in [default]\n",
      "\torg.rocksdb#rocksdbjni;6.29.5 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.21 from local-m2-cache in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   17  |   17  |   17  |   0   ||   17  |   17  |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-0fbf36a2-6aae-4f83-90e3-d3e61342df2e\n",
      "\tconfs: [default]\n",
      "\t17 artifacts copied, 0 already retrieved (574475kB/328ms)\n",
      "24/09/27 12:30:47 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/09/27 12:30:48 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark NLP version:  4.2.0\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import IntegerType, FloatType, ArrayType\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "import sparknlp\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\n",
    "        \"SentimentAnalysisRoBERTaRF\"\n",
    "    ).config(\n",
    "        \"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.12:4.2.0\"\n",
    "    ).config(\n",
    "        \"spark.executor.memory\", \"16g\"\n",
    "    ).config(\n",
    "        \"spark.driver.memory\", \"32g\"\n",
    "    ).getOrCreate()\n",
    "\n",
    "print(\"Spark NLP version: \", sparknlp.version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e2e9cfb77629cec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T04:31:31.049838Z",
     "start_time": "2024-09-27T04:30:50.571341Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+\n",
      "|label|  count|\n",
      "+-----+-------+\n",
      "|    0|2297409|\n",
      "|    1|4586529|\n",
      "|    2|2301367|\n",
      "+-----+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"../ggg_sg.csv\", header=True, inferSchema=True, multiLine=True, escape='\"')\n",
    "\n",
    "df = df.filter(df.ContextualText.isNotNull())\n",
    "df = df.filter(df.DocTone.isNotNull())\n",
    "\n",
    "df = df.withColumn(\"DocTone\", df[\"DocTone\"].cast(FloatType()))\n",
    "\n",
    "def sentiment_label(score):\n",
    "    if score > 1.9910:\n",
    "        return 2\n",
    "    elif score < -2.0202:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "sentiment_udf = udf(sentiment_label, IntegerType())\n",
    "df = df.withColumn(\"label\", sentiment_udf(col(\"DocTone\")))\n",
    "\n",
    "label_counts = df.groupBy(\"label\").count().orderBy(\"label\")\n",
    "label_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b17e71af45d5a112",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T04:38:35.821796Z",
     "start_time": "2024-09-27T04:38:18.435190Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roberta_base download started this may take some time.\n",
      "Approximate size to download 284.8 MB\n",
      "[ / ]roberta_base download started this may take some time.\n",
      "Approximate size to download 284.8 MB\n",
      "[ â€” ]Download done! Loading the resource.\n",
      "[ | ]\n",
      "An error occurred while calling z:com.johnsnowlabs.nlp.pretrained.PythonResourceDownloader.downloadModel.\n",
      ": java.lang.NoClassDefFoundError: Could not initialize class org.tensorflow.Graph\n",
      "\tat com.johnsnowlabs.ml.tensorflow.TensorflowWrapper$.readGraph(TensorflowWrapper.scala:415)\n",
      "\tat com.johnsnowlabs.ml.tensorflow.TensorflowWrapper$.unpackWithoutBundle(TensorflowWrapper.scala:330)\n",
      "\tat com.johnsnowlabs.ml.tensorflow.TensorflowWrapper$.read(TensorflowWrapper.scala:484)\n",
      "\tat com.johnsnowlabs.ml.tensorflow.ReadTensorflowModel.readTensorflowModel(TensorflowSerializeModel.scala:154)\n",
      "\tat com.johnsnowlabs.ml.tensorflow.ReadTensorflowModel.readTensorflowModel$(TensorflowSerializeModel.scala:123)\n",
      "\tat com.johnsnowlabs.nlp.embeddings.RoBertaEmbeddings$.readTensorflowModel(RoBertaEmbeddings.scala:488)\n",
      "\tat com.johnsnowlabs.nlp.embeddings.ReadRobertaTensorflowModel.readTensorflow(RoBertaEmbeddings.scala:427)\n",
      "\tat com.johnsnowlabs.nlp.embeddings.ReadRobertaTensorflowModel.readTensorflow$(RoBertaEmbeddings.scala:425)\n",
      "\tat com.johnsnowlabs.nlp.embeddings.RoBertaEmbeddings$.readTensorflow(RoBertaEmbeddings.scala:488)\n",
      "\tat com.johnsnowlabs.nlp.embeddings.ReadRobertaTensorflowModel.$anonfun$$init$$1(RoBertaEmbeddings.scala:431)\n",
      "\tat com.johnsnowlabs.nlp.embeddings.ReadRobertaTensorflowModel.$anonfun$$init$$1$adapted(RoBertaEmbeddings.scala:431)\n",
      "\tat com.johnsnowlabs.nlp.ParamsAndFeaturesReadable.$anonfun$onRead$1(ParamsAndFeaturesReadable.scala:50)\n",
      "\tat com.johnsnowlabs.nlp.ParamsAndFeaturesReadable.$anonfun$onRead$1$adapted(ParamsAndFeaturesReadable.scala:49)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat com.johnsnowlabs.nlp.ParamsAndFeaturesReadable.onRead(ParamsAndFeaturesReadable.scala:49)\n",
      "\tat com.johnsnowlabs.nlp.ParamsAndFeaturesReadable.$anonfun$read$1(ParamsAndFeaturesReadable.scala:61)\n",
      "\tat com.johnsnowlabs.nlp.ParamsAndFeaturesReadable.$anonfun$read$1$adapted(ParamsAndFeaturesReadable.scala:61)\n",
      "\tat com.johnsnowlabs.nlp.FeaturesReader.load(ParamsAndFeaturesReadable.scala:38)\n",
      "\tat com.johnsnowlabs.nlp.FeaturesReader.load(ParamsAndFeaturesReadable.scala:24)\n",
      "\tat com.johnsnowlabs.nlp.pretrained.ResourceDownloader$.downloadModel(ResourceDownloader.scala:505)\n",
      "\tat com.johnsnowlabs.nlp.pretrained.ResourceDownloader$.downloadModel(ResourceDownloader.scala:497)\n",
      "\tat com.johnsnowlabs.nlp.pretrained.PythonResourceDownloader$.downloadModel(ResourceDownloader.scala:675)\n",
      "\tat com.johnsnowlabs.nlp.pretrained.PythonResourceDownloader.downloadModel(ResourceDownloader.scala)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "[OK!]\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling z:com.johnsnowlabs.nlp.pretrained.PythonResourceDownloader.downloadModel.\n: java.lang.NoClassDefFoundError: Could not initialize class org.tensorflow.Graph\n\tat com.johnsnowlabs.ml.tensorflow.TensorflowWrapper$.readGraph(TensorflowWrapper.scala:415)\n\tat com.johnsnowlabs.ml.tensorflow.TensorflowWrapper$.unpackWithoutBundle(TensorflowWrapper.scala:330)\n\tat com.johnsnowlabs.ml.tensorflow.TensorflowWrapper$.read(TensorflowWrapper.scala:484)\n\tat com.johnsnowlabs.ml.tensorflow.ReadTensorflowModel.readTensorflowModel(TensorflowSerializeModel.scala:154)\n\tat com.johnsnowlabs.ml.tensorflow.ReadTensorflowModel.readTensorflowModel$(TensorflowSerializeModel.scala:123)\n\tat com.johnsnowlabs.nlp.embeddings.RoBertaEmbeddings$.readTensorflowModel(RoBertaEmbeddings.scala:488)\n\tat com.johnsnowlabs.nlp.embeddings.ReadRobertaTensorflowModel.readTensorflow(RoBertaEmbeddings.scala:427)\n\tat com.johnsnowlabs.nlp.embeddings.ReadRobertaTensorflowModel.readTensorflow$(RoBertaEmbeddings.scala:425)\n\tat com.johnsnowlabs.nlp.embeddings.RoBertaEmbeddings$.readTensorflow(RoBertaEmbeddings.scala:488)\n\tat com.johnsnowlabs.nlp.embeddings.ReadRobertaTensorflowModel.$anonfun$$init$$1(RoBertaEmbeddings.scala:431)\n\tat com.johnsnowlabs.nlp.embeddings.ReadRobertaTensorflowModel.$anonfun$$init$$1$adapted(RoBertaEmbeddings.scala:431)\n\tat com.johnsnowlabs.nlp.ParamsAndFeaturesReadable.$anonfun$onRead$1(ParamsAndFeaturesReadable.scala:50)\n\tat com.johnsnowlabs.nlp.ParamsAndFeaturesReadable.$anonfun$onRead$1$adapted(ParamsAndFeaturesReadable.scala:49)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat com.johnsnowlabs.nlp.ParamsAndFeaturesReadable.onRead(ParamsAndFeaturesReadable.scala:49)\n\tat com.johnsnowlabs.nlp.ParamsAndFeaturesReadable.$anonfun$read$1(ParamsAndFeaturesReadable.scala:61)\n\tat com.johnsnowlabs.nlp.ParamsAndFeaturesReadable.$anonfun$read$1$adapted(ParamsAndFeaturesReadable.scala:61)\n\tat com.johnsnowlabs.nlp.FeaturesReader.load(ParamsAndFeaturesReadable.scala:38)\n\tat com.johnsnowlabs.nlp.FeaturesReader.load(ParamsAndFeaturesReadable.scala:24)\n\tat com.johnsnowlabs.nlp.pretrained.ResourceDownloader$.downloadModel(ResourceDownloader.scala:505)\n\tat com.johnsnowlabs.nlp.pretrained.ResourceDownloader$.downloadModel(ResourceDownloader.scala:497)\n\tat com.johnsnowlabs.nlp.pretrained.PythonResourceDownloader$.downloadModel(ResourceDownloader.scala:675)\n\tat com.johnsnowlabs.nlp.pretrained.PythonResourceDownloader.downloadModel(ResourceDownloader.scala)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 16\u001b[0m\n\u001b[1;32m     10\u001b[0m stopwords_cleaner \u001b[38;5;241m=\u001b[39m StopWordsCleaner() \\\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;241m.\u001b[39msetInputCols([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \\\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;241m.\u001b[39msetOutputCol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcleanTokens\u001b[39m\u001b[38;5;124m\"\u001b[39m) \\\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;241m.\u001b[39msetCaseSensitive(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Use RoBERTa for embeddings\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m roberta_embeddings \u001b[38;5;241m=\u001b[39m RoBertaEmbeddings\u001b[38;5;241m.\u001b[39mpretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroberta_base\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m\"\u001b[39m) \\\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;241m.\u001b[39msetInputCols([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdocument\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcleanTokens\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \\\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;241m.\u001b[39msetOutputCol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m) \\\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;241m.\u001b[39msetPoolingStrategy(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Finisher will output the embeddings to a list\u001b[39;00m\n\u001b[1;32m     22\u001b[0m embeddings_finisher \u001b[38;5;241m=\u001b[39m EmbeddingsFinisher() \\\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;241m.\u001b[39msetInputCols([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \\\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;241m.\u001b[39msetOutputCols([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfinished_embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \\\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;241m.\u001b[39msetOutputAsVector(\u001b[38;5;28;01mTrue\u001b[39;00m) \\\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;241m.\u001b[39msetCleanAnnotations(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/CS5344/lib/python3.11/site-packages/sparknlp/annotator/embeddings/roberta_embeddings.py:233\u001b[0m, in \u001b[0;36mpretrained\u001b[0;34m(name, lang, remote_loc)\u001b[0m\n\u001b[1;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "File \u001b[0;32m~/anaconda3/envs/CS5344/lib/python3.11/site-packages/sparknlp/pretrained/resource_downloader.py:99\u001b[0m, in \u001b[0;36mResourceDownloader.downloadModel\u001b[0;34m(reader, name, language, remote_loc, j_dwn)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     98\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e))\n\u001b[0;32m---> 99\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    101\u001b[0m     stop_threads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/CS5344/lib/python3.11/site-packages/sparknlp/pretrained/resource_downloader.py:96\u001b[0m, in \u001b[0;36mResourceDownloader.downloadModel\u001b[0;34m(reader, name, language, remote_loc, j_dwn)\u001b[0m\n\u001b[1;32m     94\u001b[0m t1\u001b[38;5;241m.\u001b[39mstart()\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 96\u001b[0m     j_obj \u001b[38;5;241m=\u001b[39m _internal\u001b[38;5;241m.\u001b[39m_DownloadModel(reader\u001b[38;5;241m.\u001b[39mname, name, language, remote_loc, j_dwn)\u001b[38;5;241m.\u001b[39mapply()\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     98\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e))\n",
      "File \u001b[0;32m~/anaconda3/envs/CS5344/lib/python3.11/site-packages/sparknlp/internal/__init__.py:317\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, reader, name, language, remote_loc, validator)\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;28msuper\u001b[39m(_CoNLLGeneratorExportFromTargetAndPipeline, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    312\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcom.johnsnowlabs.util.CoNLLGenerator.exportConllFiles\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    313\u001b[0m         target\u001b[38;5;241m.\u001b[39m_jdf, pipeline, output_path)\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;28msuper\u001b[39m(_CoNLLGeneratorExportFromTargetAndPipeline, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    316\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcom.johnsnowlabs.util.CoNLLGenerator.exportConllFiles\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m--> 317\u001b[0m         spark\u001b[38;5;241m.\u001b[39m_jsparkSession, target, pipeline, output_path)\n",
      "File \u001b[0;32m~/anaconda3/envs/CS5344/lib/python3.11/site-packages/sparknlp/internal/extended_java_wrapper.py:26\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, java_obj, *args)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, java_obj, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28msuper\u001b[39m(ExtendedJavaWrapper, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(java_obj)\n\u001b[0;32m---> 26\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msc \u001b[38;5;241m=\u001b[39m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_java_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnew_java_obj(java_obj, \u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjava_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_java_obj\n",
      "File \u001b[0;32m~/anaconda3/envs/CS5344/lib/python3.11/site-packages/sparknlp/internal/extended_java_wrapper.py:36\u001b[0m, in \u001b[0;36mnew_java_obj\u001b[0;34m(self, java_class, *args)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_java_obj\n\u001b[0;32m---> 36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnew_java_obj\u001b[39m(\u001b[38;5;28mself\u001b[39m, java_class, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new_java_obj(java_class, \u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnew_java_array\u001b[39m(\u001b[38;5;28mself\u001b[39m, pylist, java_class):\n",
      "File \u001b[0;32m~/anaconda3/envs/CS5344/lib/python3.11/site-packages/pyspark/ml/wrapper.py:86\u001b[0m, in \u001b[0;36mJavaWrapper._new_java_obj\u001b[0;34m(java_class, *args)\u001b[0m\n\u001b[1;32m     84\u001b[0m     java_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(java_obj, name)\n\u001b[1;32m     85\u001b[0m java_args \u001b[38;5;241m=\u001b[39m [_py2java(sc, arg) \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args]\n\u001b[0;32m---> 86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m java_obj(\u001b[38;5;241m*\u001b[39mjava_args)\n",
      "File \u001b[0;32m~/anaconda3/envs/CS5344/lib/python3.11/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[1;32m   1323\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/envs/CS5344/lib/python3.11/site-packages/pyspark/errors/exceptions/captured.py:169\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    171\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m~/anaconda3/envs/CS5344/lib/python3.11/site-packages/py4j/protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling z:com.johnsnowlabs.nlp.pretrained.PythonResourceDownloader.downloadModel.\n: java.lang.NoClassDefFoundError: Could not initialize class org.tensorflow.Graph\n\tat com.johnsnowlabs.ml.tensorflow.TensorflowWrapper$.readGraph(TensorflowWrapper.scala:415)\n\tat com.johnsnowlabs.ml.tensorflow.TensorflowWrapper$.unpackWithoutBundle(TensorflowWrapper.scala:330)\n\tat com.johnsnowlabs.ml.tensorflow.TensorflowWrapper$.read(TensorflowWrapper.scala:484)\n\tat com.johnsnowlabs.ml.tensorflow.ReadTensorflowModel.readTensorflowModel(TensorflowSerializeModel.scala:154)\n\tat com.johnsnowlabs.ml.tensorflow.ReadTensorflowModel.readTensorflowModel$(TensorflowSerializeModel.scala:123)\n\tat com.johnsnowlabs.nlp.embeddings.RoBertaEmbeddings$.readTensorflowModel(RoBertaEmbeddings.scala:488)\n\tat com.johnsnowlabs.nlp.embeddings.ReadRobertaTensorflowModel.readTensorflow(RoBertaEmbeddings.scala:427)\n\tat com.johnsnowlabs.nlp.embeddings.ReadRobertaTensorflowModel.readTensorflow$(RoBertaEmbeddings.scala:425)\n\tat com.johnsnowlabs.nlp.embeddings.RoBertaEmbeddings$.readTensorflow(RoBertaEmbeddings.scala:488)\n\tat com.johnsnowlabs.nlp.embeddings.ReadRobertaTensorflowModel.$anonfun$$init$$1(RoBertaEmbeddings.scala:431)\n\tat com.johnsnowlabs.nlp.embeddings.ReadRobertaTensorflowModel.$anonfun$$init$$1$adapted(RoBertaEmbeddings.scala:431)\n\tat com.johnsnowlabs.nlp.ParamsAndFeaturesReadable.$anonfun$onRead$1(ParamsAndFeaturesReadable.scala:50)\n\tat com.johnsnowlabs.nlp.ParamsAndFeaturesReadable.$anonfun$onRead$1$adapted(ParamsAndFeaturesReadable.scala:49)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat com.johnsnowlabs.nlp.ParamsAndFeaturesReadable.onRead(ParamsAndFeaturesReadable.scala:49)\n\tat com.johnsnowlabs.nlp.ParamsAndFeaturesReadable.$anonfun$read$1(ParamsAndFeaturesReadable.scala:61)\n\tat com.johnsnowlabs.nlp.ParamsAndFeaturesReadable.$anonfun$read$1$adapted(ParamsAndFeaturesReadable.scala:61)\n\tat com.johnsnowlabs.nlp.FeaturesReader.load(ParamsAndFeaturesReadable.scala:38)\n\tat com.johnsnowlabs.nlp.FeaturesReader.load(ParamsAndFeaturesReadable.scala:24)\n\tat com.johnsnowlabs.nlp.pretrained.ResourceDownloader$.downloadModel(ResourceDownloader.scala:505)\n\tat com.johnsnowlabs.nlp.pretrained.ResourceDownloader$.downloadModel(ResourceDownloader.scala:497)\n\tat com.johnsnowlabs.nlp.pretrained.PythonResourceDownloader$.downloadModel(ResourceDownloader.scala:675)\n\tat com.johnsnowlabs.nlp.pretrained.PythonResourceDownloader.downloadModel(ResourceDownloader.scala)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n"
     ]
    }
   ],
   "source": [
    "# Create a Spark NLP pipeline\n",
    "document_assembler = DocumentAssembler() \\\n",
    "    .setInputCol(\"ContextualText\") \\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "tokenizer = Tokenizer() \\\n",
    "    .setInputCols([\"document\"]) \\\n",
    "    .setOutputCol(\"token\")\n",
    "\n",
    "stopwords_cleaner = StopWordsCleaner() \\\n",
    "    .setInputCols([\"token\"]) \\\n",
    "    .setOutputCol(\"cleanTokens\") \\\n",
    "    .setCaseSensitive(False)\n",
    "\n",
    "# Use RoBERTa for embeddings\n",
    "roberta_embeddings = RoBertaEmbeddings.pretrained(\"roberta_base\", \"en\") \\\n",
    "    .setInputCols([\"document\", \"cleanTokens\"]) \\\n",
    "    .setOutputCol(\"embeddings\") \\\n",
    "    .setPoolingStrategy(\"mean\")\n",
    "\n",
    "# Finisher will output the embeddings to a list\n",
    "embeddings_finisher = EmbeddingsFinisher() \\\n",
    "    .setInputCols([\"embeddings\"]) \\\n",
    "    .setOutputCols([\"finished_embeddings\"]) \\\n",
    "    .setOutputAsVector(True) \\\n",
    "    .setCleanAnnotations(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bc75106172a2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# Create a feature vector\n",
    "vector_assembler = VectorAssembler(inputCols=[\"finished_embeddings\"], outputCol=\"features\")\n",
    "\n",
    "pipeline = Pipeline(stages=[\n",
    "    document_assembler,\n",
    "    tokenizer,\n",
    "    stopwords_cleaner,\n",
    "    roberta_embeddings,\n",
    "    embeddings_finisher,\n",
    "    vector_assembler\n",
    "])\n",
    "\n",
    "(trainingData, testData) = df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "pipelineModel = pipeline.fit(trainingData)\n",
    "trainingData = pipelineModel.transform(trainingData)\n",
    "testData = pipelineModel.transform(testData)\n",
    "\n",
    "rf = RandomForestClassifier(featuresCol='features', labelCol='label', numTrees=50, maxDepth=10)\n",
    "\n",
    "rfModel = rf.fit(trainingData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c79e4c91e6e3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = rfModel.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2196191f8750db",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test Accuracy = %g \" % accuracy)\n",
    "\n",
    "precision_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedPrecision\")\n",
    "recall_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
    "f1_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "\n",
    "precision = precision_evaluator.evaluate(predictions)\n",
    "recall = recall_evaluator.evaluate(predictions)\n",
    "f1 = f1_evaluator.evaluate(predictions)\n",
    "\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "predictions.select(\"ContextualText\", \"label\", \"prediction\").show(10, truncate=50)\n",
    "\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
