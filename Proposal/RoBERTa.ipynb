{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import IntegerType, FloatType, ArrayType\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "import sparknlp\n",
    "from sparknlp.base import DocumentAssembler\n",
    "from sparknlp.annotator import Tokenizer, StopWordsCleaner, RoBertaEmbeddings, EmbeddingsFinisher\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\n",
    "        \"SentimentAnalysisRoBERTaRF\"\n",
    "    ).config(\n",
    "        \"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.12:4.2.0\"\n",
    "    ).config(\n",
    "        \"spark.executor.memory\", \"16g\"\n",
    "    ).config(\n",
    "        \"spark.driver.memory\", \"32g\"\n",
    "    ).getOrCreate()\n",
    "\n",
    "print(\"Spark NLP version: \", sparknlp.version())"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df = spark.read.csv(\"../ggg_sg.csv\", header=True, inferSchema=True, multiLine=True, escape='\"')\n",
    "\n",
    "df = df.filter(df.ContextualText.isNotNull())\n",
    "df = df.filter(df.DocTone.isNotNull())\n",
    "\n",
    "df = df.withColumn(\"DocTone\", df[\"DocTone\"].cast(FloatType()))\n",
    "\n",
    "def sentiment_label(score):\n",
    "    if score > 1.9910:\n",
    "        return 2\n",
    "    elif score < -2.0202:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "sentiment_udf = udf(sentiment_label, IntegerType())\n",
    "df = df.withColumn(\"label\", sentiment_udf(col(\"DocTone\")))\n",
    "\n",
    "label_counts = df.groupBy(\"label\").count().orderBy(\"label\")\n",
    "label_counts.show()"
   ],
   "id": "4e2e9cfb77629cec"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create a Spark NLP pipeline\n",
    "document_assembler = DocumentAssembler() \\\n",
    "    .setInputCol(\"ContextualText\") \\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "tokenizer = Tokenizer() \\\n",
    "    .setInputCols([\"document\"]) \\\n",
    "    .setOutputCol(\"token\")\n",
    "\n",
    "stopwords_cleaner = StopWordsCleaner() \\\n",
    "    .setInputCols([\"token\"]) \\\n",
    "    .setOutputCol(\"cleanTokens\") \\\n",
    "    .setCaseSensitive(False)\n",
    "\n",
    "# Use RoBERTa for embeddings\n",
    "roberta_embeddings = RoBertaEmbeddings.pretrained(\"roberta_base\", \"en\") \\\n",
    "    .setInputCols([\"document\", \"cleanTokens\"]) \\\n",
    "    .setOutputCol(\"embeddings\") \\\n",
    "    .setPoolingStrategy(\"mean\")\n",
    "\n",
    "# Finisher will output the embeddings to a list\n",
    "embeddings_finisher = EmbeddingsFinisher() \\\n",
    "    .setInputCols([\"embeddings\"]) \\\n",
    "    .setOutputCols([\"finished_embeddings\"]) \\\n",
    "    .setOutputAsVector(True) \\\n",
    "    .setCleanAnnotations(False)"
   ],
   "id": "b17e71af45d5a112"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# Create a feature vector\n",
    "vector_assembler = VectorAssembler(inputCols=[\"finished_embeddings\"], outputCol=\"features\")\n",
    "\n",
    "pipeline = Pipeline(stages=[\n",
    "    document_assembler,\n",
    "    tokenizer,\n",
    "    stopwords_cleaner,\n",
    "    roberta_embeddings,\n",
    "    embeddings_finisher,\n",
    "    vector_assembler\n",
    "])\n",
    "\n",
    "(trainingData, testData) = df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "pipelineModel = pipeline.fit(trainingData)\n",
    "trainingData = pipelineModel.transform(trainingData)\n",
    "testData = pipelineModel.transform(testData)\n",
    "\n",
    "rf = RandomForestClassifier(featuresCol='features', labelCol='label', numTrees=50, maxDepth=10)\n",
    "\n",
    "rfModel = rf.fit(trainingData)\n"
   ],
   "id": "20bc75106172a2d4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "predictions = rfModel.transform(testData)",
   "id": "69c79e4c91e6e3bd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test Accuracy = %g \" % accuracy)\n",
    "\n",
    "precision_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedPrecision\")\n",
    "recall_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
    "f1_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "\n",
    "precision = precision_evaluator.evaluate(predictions)\n",
    "recall = recall_evaluator.evaluate(predictions)\n",
    "f1 = f1_evaluator.evaluate(predictions)\n",
    "\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "predictions.select(\"ContextualText\", \"label\", \"prediction\").show(10, truncate=50)\n",
    "\n",
    "spark.stop()"
   ],
   "id": "f2196191f8750db"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
