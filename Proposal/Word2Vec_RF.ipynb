{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5359eaed83bf92ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T08:30:40.074150Z",
     "start_time": "2024-09-27T06:39:32.839246Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/09/27 14:39:34 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/09/27 14:49:27 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "24/09/27 16:21:52 WARN DAGScheduler: Broadcasting large task binary with size 1176.7 KiB\n",
      "24/09/27 16:23:28 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "24/09/27 16:25:13 WARN DAGScheduler: Broadcasting large task binary with size 4.3 MiB\n",
      "24/09/27 16:27:34 WARN DAGScheduler: Broadcasting large task binary with size 1241.4 KiB\n",
      "24/09/27 16:27:35 WARN DAGScheduler: Broadcasting large task binary with size 8.3 MiB\n",
      "24/09/27 16:30:37 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, udf, when, isnan, isnull\n",
    "from pyspark.sql.types import IntegerType, StringType, FloatType\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF, StringIndexer\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import Word2Vec\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "spark = SparkSession.builder.appName(\n",
    "            \"SentimentAnalysisBaseline\"\n",
    "        ).config(\n",
    "            \"spark.executor.memory\", \"16g\"\n",
    "        ).config(\n",
    "            \"spark.driver.memory\", \"32g\"\n",
    "        ).getOrCreate()\n",
    "\n",
    "df = spark.read.csv(\"../ggg_sg.csv\", header=True, inferSchema=True, multiLine=True, escape='\"')\n",
    "df = df.filter(df.ContextualText.isNotNull())\n",
    "df = df.filter(df.DocTone.isNotNull())\n",
    "df = df.withColumn(\"DocTone\", df[\"DocTone\"].cast(FloatType()))\n",
    "# Create sentiment label: Positive (2), Neutral (1), Negative (0)\n",
    "def sentiment_label(score):\n",
    "    if score > 1.9910:\n",
    "        return 2\n",
    "    elif score < -2.0202:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "sentiment_udf = udf(sentiment_label, IntegerType())\n",
    "\n",
    "df = df.withColumn(\"label\", sentiment_udf(col(\"DocTone\")))\n",
    "tokenizer = Tokenizer(inputCol=\"ContextualText\", outputCol=\"words\")\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered_words\")\n",
    "# Feature extraction (Word2Vec)\n",
    "word2Vec = Word2Vec(vectorSize=100, minCount=5, inputCol=\"filtered_words\", outputCol=\"features\")\n",
    "\n",
    "pipeline = Pipeline(stages=[tokenizer, remover, word2Vec])\n",
    "(trainingData, testData) = df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "pipelineModel = pipeline.fit(trainingData)\n",
    "trainingData = pipelineModel.transform(trainingData)\n",
    "testData = pipelineModel.transform(testData)\n",
    "\n",
    "# Random Forest model\n",
    "rf = RandomForestClassifier(featuresCol='features', labelCol='label', numTrees=50, maxDepth=10, seed=42)\n",
    "\n",
    "rfModel = rf.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb4601f191f29f12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T08:39:08.020835Z",
     "start_time": "2024-09-27T08:30:40.249766Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/27 16:30:40 WARN DAGScheduler: Broadcasting large task binary with size 5.8 MiB\n",
      "24/09/27 16:32:36 WARN DAGScheduler: Broadcasting large task binary with size 5.8 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy = 0.679253 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/27 16:34:33 WARN DAGScheduler: Broadcasting large task binary with size 5.8 MiB\n",
      "24/09/27 16:36:30 WARN DAGScheduler: Broadcasting large task binary with size 5.8 MiB\n",
      "24/09/27 16:38:30 WARN DAGScheduler: Broadcasting large task binary with size 5.8 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.7093272180121379\n",
      "Recall: 0.6792528027519265\n",
      "F1 Score: 0.6667760421736545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 42:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------+-----+----------+\n",
      "|                                    ContextualText|label|prediction|\n",
      "+--------------------------------------------------+-----+----------+\n",
      "|blink asiaone forum work crime woman gets 7 yrs...|    0|       1.0|\n",
      "|1 fetch object currentpost scrollintoview true ...|    0|       1.0|\n",
      "|scrollintoview true vbimageresize blink asiaone...|    0|       0.0|\n",
      "|b c re letters government must step up enforcem...|    0|       0.0|\n",
      "|in september re city harvest church appeal case...|    2|       1.0|\n",
      "|1 fetch object currentpost scrollintoview true ...|    1|       1.0|\n",
      "|last edited by isingapore yesterday at 11 14 pm...|    0|       1.0|\n",
      "|air denies forcing job applicants to strip down...|    0|       0.0|\n",
      "|career a current affair ben mccormack built a r...|    0|       0.0|\n",
      "|big start small act fast civil servants told by...|    1|       1.0|\n",
      "+--------------------------------------------------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "predictions = rfModel.transform(testData)\n",
    "# Evaluate model\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test Accuracy = %g \" % accuracy)\n",
    "\n",
    "# Detailed evaluation\n",
    "evaluator_precision = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedPrecision\")\n",
    "precision = evaluator_precision.evaluate(predictions)\n",
    "\n",
    "evaluator_recall = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
    "recall = evaluator_recall.evaluate(predictions)\n",
    "\n",
    "evaluator_f1 = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "f1 = evaluator_f1.evaluate(predictions)\n",
    "\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "predictions.select(\"ContextualText\", \"label\", \"prediction\").show(10, truncate=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356b793922b9c18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T08:39:08.118637Z",
     "start_time": "2024-09-27T08:39:08.117264Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "v",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
