{
 "cells": [
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-09-27T06:25:29.719413Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, udf, when, isnan, isnull\n",
    "from pyspark.sql.types import IntegerType, StringType, FloatType\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF, StringIndexer\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import Word2Vec\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "spark = SparkSession.builder.appName(\n",
    "            \"SentimentAnalysisBaseline\"\n",
    "        ).config(\n",
    "            \"spark.executor.memory\", \"16g\"\n",
    "        ).config(\n",
    "            \"spark.driver.memory\", \"32g\"\n",
    "        ).getOrCreate()\n",
    "\n",
    "df = spark.read.csv(\"../ggg_sg.csv\", header=True, inferSchema=True, multiLine=True, escape='\"')\n",
    "df = df.filter(df.ContextualText.isNotNull())\n",
    "df = df.filter(df.DocTone.isNotNull())\n",
    "df = df.withColumn(\"DocTone\", df[\"DocTone\"].cast(FloatType()))\n",
    "# Create sentiment label: Positive (2), Neutral (1), Negative (0)\n",
    "def sentiment_label(score):\n",
    "    if score > 1.9910:\n",
    "        return 2\n",
    "    elif score < -2.0202:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "sentiment_udf = udf(sentiment_label, IntegerType())\n",
    "\n",
    "df = df.withColumn(\"label\", sentiment_udf(col(\"DocTone\")))\n",
    "tokenizer = Tokenizer(inputCol=\"ContextualText\", outputCol=\"words\")\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered_words\")\n",
    "# Feature extraction (Word2Vec)\n",
    "word2Vec = Word2Vec(vectorSize=100, minCount=5, inputCol=\"filtered_words\", outputCol=\"features\")\n",
    "\n",
    "pipeline = Pipeline(stages=[tokenizer, remover, word2Vec])\n",
    "(trainingData, testData) = df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "pipelineModel = pipeline.fit(trainingData)\n",
    "trainingData = pipelineModel.transform(trainingData)\n",
    "testData = pipelineModel.transform(testData)\n",
    "\n",
    "# Random Forest model\n",
    "rf = RandomForestClassifier(featuresCol='features', labelCol='label', numTrees=50, maxDepth=10, seed=42)\n",
    "\n",
    "rfModel = rf.fit(trainingData)"
   ],
   "id": "5359eaed83bf92ba",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/27 14:25:29 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n",
      "[Stage 5:>                                                          (0 + 1) / 1]\r"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "predictions = rfModel.transform(testData)\n",
    "# Evaluate model\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test Accuracy = %g \" % accuracy)\n",
    "\n",
    "# Detailed evaluation\n",
    "evaluator_precision = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedPrecision\")\n",
    "precision = evaluator_precision.evaluate(predictions)\n",
    "\n",
    "evaluator_recall = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
    "recall = evaluator_recall.evaluate(predictions)\n",
    "\n",
    "evaluator_f1 = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "f1 = evaluator_f1.evaluate(predictions)\n",
    "\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "predictions.select(\"ContextualText\", \"label\", \"prediction\").show(10, truncate=50)"
   ],
   "id": "cb4601f191f29f12"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "356b793922b9c18"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
